{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for using `align_represenatations.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from src.align_representations import Representation, AlignRepresentations, OptimizationConfig, VisualizationConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "you can choose the following data\n",
    "1. 'DNN': representations of 2000 imagenet images in AlexNet and VGG19\n",
    "1. 'color': human similarity judgements of 93 colors for 5 paricipants groups\n",
    "1. 'face': human similarity judgements of 16 faces, attended vs unattended condition in the same participant\n",
    "1. 'THINGS' : human similarity judgements of 1854 objects for 4 paricipants groups\n",
    "\n",
    "\n",
    "\"data_select\" in next code block can define which dataset are going to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = \"THINGS\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set some parameters used later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set Representations\n",
    "    - A Representation needs a name and either an embedding or a similarity matrix.\n",
    "'''\n",
    "# Parameters\n",
    "n_representations = 4 # Set the number of representations. This number must be equal to or less than the number of groups.\n",
    "metric = \"euclidean\"\n",
    "\n",
    "# representations list that will be used in Align_Representations\n",
    "representations = list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No1. `color`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create representations instance\n",
    "if data_select == 'color':\n",
    "    category_mat = None\n",
    "    data_path = '../data/num_groups_5_seed_0_fill_val_3.5.pickle'\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    sim_mat_list = data[\"group_ave_mat\"]\n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\"\n",
    "        sim_mat = sim_mat_list[i]\n",
    "        representation = Representation(name = name, sim_mat = sim_mat)\n",
    "        representations.append(representation)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No.2 `THINGS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    # define the label information of the dataset\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)\n",
    "    \n",
    "    # define the parameters for label info. \n",
    "    # Users can define these by themselves if they use a different dataset and the format of parameters are the same.\n",
    "    from src.utils.utils_functions import get_category_data, sort_matrix_with_categories\n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat)\n",
    "    \n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\"\n",
    "        embedding = np.load(f\"../data/THINGS_embedding_Group{i+1}.npy\")[0]\n",
    "        \n",
    "        representation = Representation(\n",
    "            name = name, \n",
    "            embedding = embedding, \n",
    "            metric = metric, \n",
    "            object_labels = object_labels,\n",
    "            category_name_list = category_name_list,\n",
    "            category_idx_list = category_idx_list,\n",
    "            num_category_list = num_category_list,\n",
    "            func_for_sort_sim_mat = sort_matrix_with_categories\n",
    "        )\n",
    "        \n",
    "        representations.append(representation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the parameters for the optimazation of GWOT, and the parameters for visualizing matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = OptimizationConfig(\n",
    "    data_name = data_select, \n",
    "    delete_study = False, \n",
    "    device = 'cpu',\n",
    "    to_types = 'numpy',\n",
    "    n_jobs = 4,\n",
    "    init_plans_list = ['random'],\n",
    "    num_trial = 4,\n",
    "    n_iter = 1,\n",
    "    max_iter = 200,\n",
    "    sampler_name = 'tpe',\n",
    "    eps_list = [1, 10], # [1, 10] for THINGS data, [0.02, 0.2] for colors data\n",
    "    eps_log = True,\n",
    "    pruner_name = 'hyperband',\n",
    "    pruner_params = {'n_startup_trials': 1, \n",
    "                     'n_warmup_steps': 2, \n",
    "                     'min_resource': 2, \n",
    "                     'reduction_factor' : 3\n",
    "                    }\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised alignment between Representations\n",
    "    - The object has methods for RSA, GW-alignment, evaluation of the alignment and visalization of aligned embeddings.\n",
    "    - The parameter \"shuffle\" means a method is applied for a shuffled similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the instance\n",
    "align_representation = AlignRepresentations(representations_list = representations, config = config)\n",
    "\n",
    "# RSA\n",
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "    visualize_matrix = VisualizationConfig(figsize=(10, 10), title_size = 15, category_line_alpha = 0.5, draw_category_line=True)\n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format = sim_mat_format, \n",
    "        visualization_config = visualize_matrix,\n",
    "        ticks='category'\n",
    "    )\n",
    "\n",
    "if data_select == \"color\":\n",
    "    sim_mat_format = \"default\"\n",
    "    visualize_matrix = VisualizationConfig(figsize=(10, 10), title_size = 15)\n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format = sim_mat_format, \n",
    "        visualization_config = visualize_matrix,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_representation.RSA_get_corr(method = 'all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing GW Alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "    visualize_matrix = VisualizationConfig(figsize=(10, 10), title_size = 15, category_line_color = 'C1')\n",
    "\n",
    "    ot_list = align_representation.gw_alignment(\n",
    "        results_dir = \"../results\",\n",
    "        compute_again = False,  # If the computation was done and no need for, turn \"compute_again\" False, then OT plans calculated before is loaded.\n",
    "        return_data = False,\n",
    "        return_figure = True,\n",
    "        OT_format = sim_mat_format, \n",
    "        visualization_config = visualize_matrix,\n",
    "        ticks = 'category', # you can use \"objects\" or \"category\" or \"None\"\n",
    "        use_parallel=True, # both for numpy and torch. the parallel computation is done by \"ThreadPoolExecutor\" from \"concurrent\" by Python.\n",
    "        multi_gpu=False, # \"True\" : all the GPU installed in your environment, \"list (e.g.[0,2,3])\"\" : cuda:0,2,3, and \"False\" : single gpu (or cpu for numpy) will use for parallel computation.\n",
    "    )\n",
    "\n",
    "if data_select == \"color\":\n",
    "    visualize_matrix = VisualizationConfig(figsize=(10, 10), title_size = 15)\n",
    "\n",
    "    align_representation.gw_alignment(\n",
    "        results_dir = \"../results\",\n",
    "        compute_again = False,\n",
    "        return_data = False,\n",
    "        return_figure = True,\n",
    "        OT_format = sim_mat_format, # \"default\"\n",
    "        visualization_config = visualize_matrix,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align embeddings with OT plans and Visualize the aligned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the accuracy of the optimized OT matrix\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"ot_plan\")\n",
    "align_representation.plot_accuracy(eval_type = \"ot_plan\", scatter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the matching rate of k-nearest neighbors of embeddings\n",
    "## Matching rate of k-nearest neighbors \n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"k_nearest\")\n",
    "align_representation.plot_accuracy(eval_type = \"k_nearest\", scatter = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## category level analysis \n",
    "User can use this analysis if the dataset has category info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calclate the category level accuracy\n",
    "if data_select == \"THINGS\":\n",
    "    align_representation.calc_category_level_accuracy(category_mat=category_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color labels and category data if exist.\n",
    "if data_select == \"THINGS\":\n",
    "    category_name_list = [\"bird\", \"insect\", \"plant\", \"clothing\",  \"furniture\", \"fruit\", \"drink\", \"vehicle\"]\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)   \n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat, category_name_list, show_numbers = True)  \n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim = 3,  \n",
    "        category_name_list = category_name_list, \n",
    "        category_idx_list = category_idx_list, \n",
    "        num_category_list = num_category_list,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
