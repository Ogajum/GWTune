{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for using `align_represenatations.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from src.align_representations import Representation, Pairwise_Analysis, Align_Representations, Optimization_Config, Visualize_Matrix\n",
    "from src.utils.utils_functions import get_category_idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "you can choose the following data\n",
    "1. 'DNN': representations of 2000 imagenet images in AlexNet and VGG19\n",
    "1. 'color': human similarity judgements of 93 colors for 5 paricipants groups\n",
    "1. 'face': human similarity judgements of 16 faces, attended vs unattended condition in the same participant\n",
    "1. 'THINGS' : human similarity judgements of 1854 objects for 4 paricipants groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = \"THINGS\"\n",
    "\n",
    "'''\n",
    "Set Representations\n",
    "    - A Representation needs a name and either an embedding or a similarity matrix.\n",
    "'''\n",
    "# Parameters\n",
    "n_representations = 4 # Set the number of representations. This number must be equal to or less than the number of groups.\n",
    "metric = \"euclidean\"\n",
    "\n",
    "# representations list that will be used in Align_Representations\n",
    "representations = list()\n",
    "\n",
    "# Load data and create representations instance\n",
    "if data_select == 'color':\n",
    "    data_path = '../data/num_groups_5_seed_0_fill_val_3.5.pickle'\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    sim_mat_list = data[\"group_ave_mat\"]\n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\"\n",
    "        sim_mat = sim_mat_list[i]\n",
    "        representation = Representation(name = name, sim_mat = sim_mat)\n",
    "        representations.append(representation)\n",
    "\n",
    "elif data_select == \"THINGS\":\n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\"\n",
    "        embedding = np.load(f\"../data/THINGS_embedding_Group{i+1}.npy\")[0]\n",
    "        category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)  \n",
    "        representation = Representation(name = name, embedding = embedding, metric = metric, category_mat = category_mat)\n",
    "        representations.append(representation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the parameters for the optimazation of GWOT, and the parameters for visualizing matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = Optimization_Config(data_name = data_select, \n",
    "                             delete_study = False, \n",
    "                             device = 'cpu',\n",
    "                             to_types = 'numpy',\n",
    "                             n_jobs = 1,\n",
    "                             init_plans_list = ['random'],\n",
    "                             num_trial = 4,\n",
    "                             n_iter = 1,\n",
    "                             max_iter = 200,\n",
    "                             sampler_name = 'tpe',\n",
    "                             eps_list = [1, 10], # [1, 10] for THINGS data, [0.02, 0.2] for colors data\n",
    "                             eps_log = True,\n",
    "                             pruner_name = 'hyperband',\n",
    "                             pruner_params = {'n_startup_trials': 1, 'n_warmup_steps': 2, 'min_resource': 2, 'reduction_factor' : 3}\n",
    "                             )\n",
    "\n",
    "visualize_matrix = Visualize_Matrix()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised alignment between Representations\n",
    "    - The object has methods for RSA, GW-alignment, evaluation of the alignment and visalization of aligned embeddings.\n",
    "    - The parameter \"shuffle\" means a method is applied for a shuffled similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the instance\n",
    "align_representation = Align_Representations(representations_list = representations, config = config)\n",
    "\n",
    "# RSA\n",
    "sim_mat = align_representation.show_sim_mat(returned = \"figure\", sim_mat_format = \"sorted\", visualize_matrix = visualize_matrix)#fig_dir = \"../figures\")\n",
    "align_representation.RSA_get_corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing GW Alignment in the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If no need for computation, turn load_OT True, then OT plans calculated before is loaded.\n",
    "align_representation.gw_alignment(load_OT = True, returned = \"figure\", OT_format = \"sorted\", visualize_matrix = visualize_matrix)\n",
    "\n",
    "## Calculate the accuracy of the optimized OT matrix\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"ot_plan\")\n",
    "align_representation.plot_accuracy(eval_type = \"ot_plan\", scatter = True)\n",
    "\n",
    "## Calclate the category level accuracy\n",
    "align_representation.calc_category_level_accuracy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align embeddings with OT plans and Visualize the aligned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Calculate the matching rate of k-nearest neighbors of embeddings\n",
    "## Matching rate of k-nearest neighbors \n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"k_nearest\")\n",
    "align_representation.plot_accuracy(eval_type = \"k_nearest\", scatter = True)\n",
    "\n",
    "\n",
    "# Set color labels and category data if exist.\n",
    "if data_select == \"THINGS\":\n",
    "    color_labels = None\n",
    "    category_name_list = [\"bird\", \"insect\", \"plant\", \"clothing\",  \"furniture\", \"fruit\", \"drink\", \"vehicle\"]\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)   \n",
    "    category_idx_list, category_num_list = get_category_idx(category_mat, category_name_list, show_numbers = True)  \n",
    "    align_representation.visualize_embedding(dim = 3, color_labels = color_labels, category_name_list = category_name_list, category_idx_list = category_idx_list, category_num_list = category_num_list)#, fig_dir = \"../figures\")\n",
    "elif data_select == \"color\":\n",
    "    file_path = \"../data/color_dict.csv\"\n",
    "    data_color = pd.read_csv(file_path)\n",
    "    color_labels = data_color.columns.values\n",
    "    align_representation.visualize_embedding(dim = 3, color_labels = color_labels)#, fig_dir = \"../figures\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
