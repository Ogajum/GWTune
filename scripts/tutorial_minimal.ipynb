{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b129330d",
   "metadata": {},
   "source": [
    "# Brief Tutorial on Extracting Optuna Study\n",
    "This notebook is intended to introduce the minimal functions needed to perform the GWOT optimization.    \n",
    "For most users, using `align_representations.py`, as demonstrated in our main tutorial `tutorial.ipynb`, will be sufficient.   \n",
    "However, this tutorial is intended for some users who want to understand how Optuna is used in this toolbox and customize the optimization process by using Optuna on their own.    \n",
    "\n",
    "This notebook briefly demonstrates how to :\n",
    "1. Use `opt.run_study` to create an Optuna study.   \n",
    "2. Extract the `best_trial` from the study.    \n",
    "\n",
    "Please make sure that you have worked through the main tutorial (`tutorial.ipynb`) before diving into this one, as this tutorial focuses only on specific objectives and assumes familiarity with the main concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9038e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import os\n",
    "import pickle as pkl\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "# Third Party Library\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sqlalchemy import URL\n",
    "\n",
    "# First Party Library\n",
    "from src.gw_alignment import GW_Alignment\n",
    "from src.utils.gw_optimizer import load_optimizer\n",
    "# os.chdir(os.path.dirname(__file__))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc537cfe",
   "metadata": {},
   "source": [
    "## Step:1 load data\n",
    "Here we use the `color` data for demonstaration.   \n",
    "`color`: human similarity judgements of 93 colors for 5 paricipants groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/color/num_groups_5_seed_0_fill_val_3.5.pickle'\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data = pkl.load(f)\n",
    "sim_mat_list = data[\"group_ave_mat\"]\n",
    "\n",
    "C1 = sim_mat_list[0]\n",
    "C2 = sim_mat_list[1]\n",
    "\n",
    "# show dissimilarity matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "im1 = axes[0].imshow(C1, cmap='rocket_r')\n",
    "cbar1 = fig.colorbar(im1, ax=axes[0], shrink=0.8)\n",
    "im2 = axes[1].imshow(C2, cmap='rocket_r')\n",
    "cbar2 = fig.colorbar(im2, ax=axes[1], shrink=0.8)\n",
    "\n",
    "axes[0].set_title('Dissimilarity matrix #1')\n",
    "axes[1].set_title('Dissmimilarity matrix #2')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9f9f038",
   "metadata": {},
   "source": [
    "## Step:2 set the parameter used for computing and saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad03a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the range of the epsilon\n",
    "# set the minimum value and maximum value for \"tpe\" sampler\n",
    "# for \"grid\" or \"random\" sampler, you can also set the step size    \n",
    "eps_list = [1e-2, 1e-1]  # [1e-2, 1e-1, 1e-3]\n",
    "device = \"cpu\"\n",
    "to_types = \"numpy\"\n",
    "\n",
    "# whether epsilon is sampled at log scale or not\n",
    "eps_log = True\n",
    "\n",
    "# Set the params for the trial of optimize and max iteration for gw alignment computation\n",
    "# set the number of trials, i.e., the number of epsilon values tested in optimization: default : 20\n",
    "num_trial = 20\n",
    "\n",
    "# the maximum number of iteration for GW optimization: default: 1000\n",
    "max_iter = 200\n",
    "\n",
    "# choose sampler\n",
    "sampler_name = 'tpe'\n",
    "\n",
    "# choose pruner\n",
    "pruner_name = 'hyperband'\n",
    "pruner_params = {'n_startup_trials': 1, 'n_warmup_steps': 2, 'min_resource': 2, 'reduction_factor' : 3}\n",
    "\n",
    "# initialization of transportation plan\n",
    "# 'uniform': uniform matrix, 'diag': diagonal matrix', random': random matrix, 'permutation': permutation matrix\n",
    "init_mat_plan = 'random'\n",
    "\n",
    "# the number of random initial matrices for 'random' or 'permutation' options：default: 100\n",
    "n_iter = 1\n",
    "\n",
    "## Set the parameters for GW alignment computation \n",
    "# please choose the method of sinkhorn implemented by POT (URL : https://pythonot.github.io/gen_modules/ot.bregman.html#id87). For using GPU, \"sinkhorn_log\" is recommended.\n",
    "sinkhorn_method='sinkhorn'\n",
    "\n",
    "# user can define the dtypes both for numpy and torch, \"float(=float32)\" or \"double(=float64)\". For using GPU with \"sinkhorn\", double is storongly recommended.\n",
    "data_type = \"double\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a755cd2a",
   "metadata": {},
   "source": [
    "### Set the filename and folder name for saving optuna results  \n",
    "filename is also treated as optuna study_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d314f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test'\n",
    "save_path = '../results/tutorial_minimal/' + filename + '/' + sampler_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34a6e8d7",
   "metadata": {},
   "source": [
    "### Set the database URL to store the optimization results.  \n",
    "\n",
    "The URL notation should follow the SQLAlchemy documentation:   \n",
    "https://docs.sqlalchemy.org/en/20/core/engines.html  \n",
    "\n",
    "To use remote databases, you need to start the database server beforehand. For detailed instruction, please refer to the Optuna official tutorial:  \n",
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html  \n",
    "\n",
    "When using SQLite, the database file is automatically created, so you only need to set the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da435546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the RDB to use for distributed calculations\n",
    "db_params={\"drivername\": \"sqlite\"} # SQLite\n",
    "# db_params={\"drivername\": \"mysql+pymysql\", \"username\": \"root\", \"password\": \"****\", \"host\": \"localhost\"} # MySQL\n",
    "\n",
    "if db_params[\"drivername\"] == \"sqlite\":\n",
    "    storage = \"sqlite:///\" + save_path +  '/' + filename + '.db'\n",
    "else:\n",
    "    # Generate the URL for the database. Syntax differs for SQLite and others.\n",
    "    storage = URL.create(database=filename, **db_params).render_as_string(hide_password=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "355d922f",
   "metadata": {},
   "source": [
    "## Step:3 Perform GW Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba535c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate instance solves gw_alignment　\n",
    "test_gw = GW_Alignment(\n",
    "    C1, \n",
    "    C2, \n",
    "    save_path, \n",
    "    max_iter = max_iter, \n",
    "    n_iter = n_iter, \n",
    "    to_types = to_types,\n",
    "    data_type = data_type,\n",
    "    sinkhorn_method = sinkhorn_method,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate instance optimize gw_alignment　\n",
    "opt = load_optimizer(\n",
    "    save_path=save_path,\n",
    "    filename=filename,\n",
    "    storage=storage,\n",
    "    init_mat_plan=init_mat_plan,\n",
    "    n_iter = n_iter,\n",
    "    num_trial = num_trial,\n",
    "    n_jobs = 1,    \n",
    "    method = 'optuna',\n",
    "    sampler_name = sampler_name,\n",
    "    pruner_name = pruner_name,\n",
    "    pruner_params = pruner_params,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15e73f39",
   "metadata": {},
   "source": [
    "### Compute GW Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Running the Optimization using `opt.run_study`\n",
    "# 2. run optimzation\n",
    "study = opt.run_study(\n",
    "    test_gw,\n",
    "    device,\n",
    "    seed=42,\n",
    "    init_mat_plan=init_mat_plan,\n",
    "    eps_list=eps_list,\n",
    "    eps_log=eps_log,\n",
    "    search_space=None,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bbf9570",
   "metadata": {},
   "source": [
    "## Step:4 View the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### View Results\n",
    "display(study.trials_dataframe().sort_values('params_eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting the Best Trial from the Study\n",
    "df_trial = study.trials_dataframe()\n",
    "best_trial = study.best_trial\n",
    "print(best_trial)\n",
    "\n",
    "# extracting optimized epsilon, GWD from best_trial\n",
    "eps_opt = best_trial.params['eps']\n",
    "GWD_opt = best_trial.values[0]\n",
    "\n",
    "# load the opitimized transportation plan from the saved file\n",
    "if to_types == 'numpy':\n",
    "    OT = np.load(save_path+f'/gw_{best_trial.number}.npy')\n",
    "elif to_types == 'torch':\n",
    "    OT = torch.load(save_path+f'/gw_{best_trial.number}.pt')\n",
    "    OT = OT.to('cpu').numpy()\n",
    "\n",
    "# plot the optimal transportation plan\n",
    "plt.imshow(OT)\n",
    "plt.title(f'OT eps:{eps_opt:.3f} GWD:{GWD_opt:.3f}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1876604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure plotting epsilon as x-axis and GWD as y-axis\n",
    "df_trial = study.trials_dataframe()\n",
    "\n",
    "plt.scatter(df_trial['params_eps'], df_trial['value'], s = 50, c=df_trial['user_attrs_best_acc'] * 100, cmap='viridis')\n",
    "plt.xlabel('$\\epsilon$')\n",
    "plt.ylabel('GWD')\n",
    "plt.colorbar(label='Matching Rate (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc85d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate accuracy of unsupervised alignment\n",
    "max_indices = np.argmax(OT, axis=1)\n",
    "accuracy = np.mean(max_indices == np.arange(OT.shape[0])) * 100\n",
    "print(f'accuracy={accuracy}%')\n",
    "\n",
    "\n",
    "#　figure plotting GWD as x-axis and accuracy as y-axis\n",
    "plt.scatter(df_trial['user_attrs_best_acc'] * 100, df_trial['value'], s = 50, c= df_trial['params_eps'])\n",
    "plt.xlabel('Matching Rate (%)')\n",
    "plt.ylabel('GWD')\n",
    "plt.colorbar(label='epsilon')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
