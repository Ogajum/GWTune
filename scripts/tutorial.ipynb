{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tutorial for Gromov-Wassserstein unsupervised alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from src.align_representations import Representation, AlignRepresentations, OptimizationConfig, VisualizationConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Prepare dissimilarity matrices or embeddings from the data\n",
    "First, you need to prepare dissimilarity matrices or embeddings from your data.  \n",
    "\n",
    "The unit of unsupervised alignment is an instance of the \"Representation\" class. This class has variables such as \"name\" and either \"sim_mat\" or \"embedding\". You need to assign values to these variables.  \n",
    "These instances are stored in \"representations\" and later passed to the \"AlignRepresentations\" class.\n",
    "\n",
    "## Load data\n",
    "You have the option to select the data from the following choices:\n",
    "1. 'color': human similarity judgements of 93 colors for 5 paricipants groups\n",
    "2. 'THINGS' : human similarity judgements of 1854 objects for 4 paricipants groups\n",
    "\n",
    "\"data_select\" in next code block determines which data is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of representations where the instances of \"Representation\" class are included\n",
    "representations = list()\n",
    "\n",
    "# select data\n",
    "data_select = \"DNN\"\n",
    "# data_select = \"THINGS\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No1. `color`\n",
    "In this case, we directly assign the dissimilarity matrices of 93 colors to \"Representation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create \"Representation\" instance\n",
    "if data_select == 'color':\n",
    "    n_representations = 3 # Set the number of the instanses of \"Representation\". This number must be equal to or less than the number of the groups. 5 is the maximum for this data.\n",
    "    metric = \"euclidean\" # Please set the metric that can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    \n",
    "    data_path = '../data/num_groups_5_seed_0_fill_val_3.5.pickle'\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    sim_mat_list = data[\"group_ave_mat\"]\n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\" # \"name\" will be used as a filename for saving the results\n",
    "        sim_mat = sim_mat_list[i] # the dissimilarity matrix of the i-th group\n",
    "        # make an instance \"Representation\" with settings \n",
    "        representation = Representation(\n",
    "            name=name, \n",
    "            metric=metric,\n",
    "            sim_mat=sim_mat,  #: np.ndarray\n",
    "            embedding=None,   #: np.ndarray \n",
    "            get_embedding=True, # If true, the embeddings are computed from the dissimilarity matrix automatically using the MDS function. Default is False. \n",
    "            MDS_dim=3, # If \"get embedding\" is True, please set the dimensions of the embeddings.\n",
    "            object_labels=None,\n",
    "            category_name_list=None,\n",
    "            num_category_list=None,\n",
    "            category_idx_list=None,\n",
    "            func_for_sort_sim_mat=None,\n",
    "       ) \n",
    "        representations.append(representation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No.2 `THINGS`\n",
    "In this case, we assign the embeddings of each object to \"Representation\". This class will compute the dissimilarity matrices with the embeddings.  \n",
    "Furthermore, this dataset includes coarse category labels for each objet, and we will now demonstrate how to utilize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    # define the coarce category labels\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)\n",
    "    \n",
    "    # calculate the parameters for the coarce category labels\n",
    "    # Please prepare equivalent parameters when using other datasets.\n",
    "    from src.utils.utils_functions import get_category_data, sort_matrix_with_categories # get_category_data and sort_matrix_with_categories are functions specialied for this dataset\n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat)\n",
    "    \n",
    "    n_representations = 3 # Set the number of the instanses of \"Representation\". This number must be equal to or less than the number of the groups. 4 is the maximum for this data.\n",
    "    metric = \"euclidean\" # Please set the metric that can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    \n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\"\n",
    "        embedding = np.load(f\"../data/THINGS_embedding_Group{i+1}.npy\")[0]\n",
    "        \n",
    "        representation = Representation(\n",
    "            name=name, \n",
    "            embedding=embedding, # the dissimilarity matrix will be computed with this embedding.\n",
    "            metric=metric,\n",
    "            get_embedding=False, # If there is the embeddings, plese set this variable \"False\".\n",
    "            object_labels=object_labels,\n",
    "            category_name_list=category_name_list,\n",
    "            category_idx_list=category_idx_list,\n",
    "            num_category_list=num_category_list,\n",
    "            func_for_sort_sim_mat=sort_matrix_with_categories\n",
    "        )\n",
    "        \n",
    "        representations.append(representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No3. `DNN`\n",
    "The latent features of two models (AlexNet and VGG19) were extracted from the image dataset ImageNet.   \n",
    "The number of image used for this was 1000 (= 10 class * 100 images) from the validation of ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == 'DNN':\n",
    "    import torch\n",
    "    path1 = '../data/model1.pt'\n",
    "    path2 = '../data/model2.pt'\n",
    "    \n",
    "    C1 = torch.load(path1).to('cpu').numpy()\n",
    "    C2 = torch.load(path2).to('cpu').numpy()\n",
    "    \n",
    "    alexnet = Representation(name=\"AlexNet\", sim_mat=C1, get_embedding=False)\n",
    "    vgg19 = Representation(name=\"VGG19\", sim_mat=C2, get_embedding=False)\n",
    "    \n",
    "    representations.append(alexnet)\n",
    "    representations.append(vgg19)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Set the parameters for the optimazation of GWOT\n",
    "\n",
    "## Optimization Config  \n",
    "\n",
    "#### Most important parameters to check for your application:\n",
    "`eps_list, num_trial` are essential for computing the GW alignment.  \n",
    "You need to choose the appropriate ranges of the epsilon, `eps_list`.  \n",
    "If the epsilon is not in the appropriate ranges, the optimization may not work properly.  \n",
    "Also, the epsilon range is critical for finding good local optimum.  \n",
    "\n",
    "For other parameters, please start by trying the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Most important parameters\n",
    "# Set the range of the epsilon\n",
    "# set the minimum value and maximum value for 'tpe' sampler\n",
    "# for 'grid' or 'random' sampler, you can also set the step size\n",
    "if data_select == \"THINGS\":\n",
    "    eps_list_tutorial = [1, 10]\n",
    "if data_select == \"color\":\n",
    "    eps_list_tutorial = [0.02, 0.2]\n",
    "if data_select == \"DNN\":\n",
    "    eps_list_tutorial = [1e-4, 1e-3]\n",
    "    \n",
    "# whether epsilon is sampled at log scale or not\n",
    "eps_log = True\n",
    "\n",
    "# set the number of trials, i.e., the number of epsilon values evaluated in optimization. default : 4\n",
    "num_trial = 4\n",
    "\n",
    "### Set the parameters for optimization\n",
    "# initialization of transportation plan\n",
    "# 'uniform': uniform matrix, 'diag': diagonal matrix', random': random matrix, 'permutation': permutation matrix\n",
    "# Select multiple options was deprecated.\n",
    "init_mat_plan = \"random\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if user wants to use some user-defined init matrices...\n",
    "For ”user_define”, it is note that all the initialization plans need to be written in Numpy even when PyTorch is used for the optimization.  \n",
    "The user can define a single or multiple plans before the optimization starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if init_mat_plan == \"user_define\":\n",
    "    import ot\n",
    "    size = representation.sim_mat.shape[0]\n",
    "    user_define_mat_random = np.random.randn(size, size)\n",
    "    user_define_mat_random = user_define_mat_random / user_define_mat_random.sum()\n",
    "    user_define_init_mat_list = [user_define_mat_random, np.outer(ot.unif(size), ot.unif(size))]\n",
    "\n",
    "else:\n",
    "    user_define_init_mat_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OptimizationConfig(    \n",
    "    eps_list = eps_list_tutorial, # [1, 10] for THINGS data, [0.02, 0.2] for colors data\n",
    "    eps_log = eps_log, # whether epsilon is sampled at log scale or not\n",
    "    num_trial = num_trial, # set the number of trials, i.e., the number of epsilon values evaluated in optimization. default : 4\n",
    "    sinkhorn_method='sinkhorn', # please choose the method of sinkhorn implemented by POT (URL : https://pythonot.github.io/gen_modules/ot.bregman.html#id87). For using GPU, \"sinkhorn_log\" is recommended.\n",
    "    \n",
    "    ### Set the device ('cuda' or 'cpu') and variable type ('torch' or 'numpy')\n",
    "    to_types = 'torch', # user can choose \"numpy\" or \"torch\". please set \"torch\" if one wants to use GPU.\n",
    "    device = 'cuda', # \"cuda\" or \"cpu\"; for numpy, only \"cpu\" can be used. \n",
    "    data_type = \"double\", # user can define the dtypes both for numpy and torch, \"float(=float32)\" or \"double(=float64)\". For using GPU with \"sinkhorn\", double is storongly recommended.\n",
    "    \n",
    "    ### Parallel Computation (requires n_jobs > 1, available both for numpy and torch)\n",
    "    n_jobs = 3, # n_jobs : the number of worker to compute. if n_jobs = 1, normal computation will start. \"Multithread\" is used for Parallel computation.\n",
    "    multi_gpu = True, # This parameter is only for \"torch\". # \"True\" : all the GPU installed in your environment are used, \"list (e.g.[0,2,3])\"\" : cuda:0,2,3, and \"False\" : single gpu (or cpu for numpy) will use.\n",
    "    \n",
    "    ### Set the db_params to create database URL to store the optimization results (either PyMySQL or SQLite. For using PyMySQL, some additional setting beforehand will be needed).  \n",
    "    # The database URL in sqlalchemy is like \"dialect+driver://username:password@host:port/database\". See the following page for details. https://docs.sqlalchemy.org/en/20/core/engines.html\n",
    "    # If you want to use SQLite, it's enough to set \"db_params={\"drivername\": \"sqlite\"}\".\n",
    "    # This package generates 1 database per each study.\n",
    "\n",
    "    db_params={\"drivername\": \"sqlite\"},\n",
    "    # db_params={\"drivername\": \"mysql+pymysql\", \"username\": \"root\", \"password\": \"****\", \"host\": \"localhost\"},\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # 'uniform': uniform matrix, 'diag': diagonal matrix', random': random matrix\n",
    "    init_mat_plan = init_mat_plan,\n",
    "    \n",
    "    # user-defined initialization plans\n",
    "    user_define_init_mat_list = user_define_init_mat_list,\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # n_iter : the number of random initial matrices for 'random' or 'permutation' options：default: 1\n",
    "    # max_iter : the maximum number of iteration for GW optimization: default: 200\n",
    "    n_iter = 1,\n",
    "    max_iter = 200,\n",
    "    \n",
    "    ### choose sampler implemented by Optuna\n",
    "    # 1. 'random': randomly select epsilon between the range of epsilon\n",
    "    # 2. 'grid': grid search between the range of epsilon\n",
    "    # 3. 'tpe': Bayesian sampling\n",
    "    sampler_name = 'tpe',\n",
    "    \n",
    "    ### choose pruner\n",
    "    # 1. 'median': Pruning if the score is below the past median at a certain point in time  \n",
    "    #     n_startup_trials: Do not activate the pruner until this number of trials has finished  \n",
    "    #     n_warmup_steps: Do not activate the pruner for each trial below this step  \n",
    "        \n",
    "    # 2. 'hyperband': Use multiple SuccessiveHalvingPrunerd that gradually longer pruning decision periods and that gradually stricter criteria  \n",
    "    #     min_resource: Do not activate the pruner for each trial below this step  \n",
    "    #     reduction_factor: How often to check for pruning. Smaller values result in more frequent pruning checks. Between 2 to 6.  \n",
    "        \n",
    "    # 3. 'nop': no pruning\n",
    "    pruner_name = 'hyperband',\n",
    "    pruner_params = {'n_startup_trials': 1, \n",
    "                     'n_warmup_steps': 2, \n",
    "                     'min_resource': 2, \n",
    "                     'reduction_factor' : 3\n",
    "                    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Unsupervised alignment between Representations\n",
    "\"AlignRepresentations\" is the class for performing the unsupervised alignment among the instanses of \"Representation\".  \n",
    "This class has methods for Representation Similarity Analysis (RSA), Gromov-Wasserstein (GW) alignment, and the evaluation of the GW alignment. \n",
    "\n",
    "By default, the instance applis GW alignment to all pairs in the `representations` defined at the begining of this notebook.   \n",
    "If you want to limit the pairs to which GW alignment is applied, please set “AlignRepresentations.pair_number_list”. (e.g. pair_number_list = [[0, 1], [0, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The directory structure of this toolbox\n",
    "\n",
    "Here is the directory structure of this toolbox below.  \n",
    "\n",
    "```\n",
    "    main_results_dir /\n",
    "        ├─ data_name (e.g. `THINGS`) /\n",
    "            ├─ data_name + pair_name (e.g. `THINGS_Group1_vs_Group2`) /\n",
    "                ├─ sampler_name (e.g. `random`) /\n",
    "                    ├─ figure /\n",
    "                    │   ├─ some figures (e.g. acc_gwd_eps.png)\n",
    "                    ├─ data /\n",
    "                    │   ├─ OT.npy (numpy) or OT.pt (torch)\n",
    "                    │   \n",
    "                    ├─ database (if using sqlite; e.g. `THINGS_Group1_vs_Group2_random.db`)\n",
    "``` \n",
    "--- \n",
    "- The folder structure `main_results_dir/data_name` will be built once `AlignRepresentations` was loaded.\n",
    "\n",
    "- User is assumed to define the `main_result_dir` only in `AlignRepresentations`, then, the code will automatically made the structure below.\n",
    "\n",
    "- We provide some lists (`results_dir_list` , `pair_name_list`, `file_name_list`) to define the name of files and/or folders in the directory structure by user. \n",
    "  - results_dir_list : this can re-define the `main_results_dir` for each pair. \n",
    "\n",
    "  - pair_name_list : this can re-define the name of `pair_name` in the structure above.\n",
    "  \n",
    "  - file_name_list : this can re-define the name of folder `data_name + pair_name` in the structure above.  \n",
    "  \n",
    "  - It's recommended to assign the name and/or directory to each pair in these list when making the `representations` list above if user wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an \"AlignRepresentations\" instance\n",
    "align_representation = AlignRepresentations(\n",
    "    config=config,\n",
    "    representations_list=representations,\n",
    "    \n",
    "    histogram_matching=False,\n",
    "    \n",
    "    metric=\"cosine\", # The metric for computing the distance between the embeddings. Please set the metric tha can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    pair_number_list=\"all\", # If you want to limit the pairs to which GW alignment is applied, please set “AlignRepresentations.pair_number_list”. (e.g. pair_number_list = [[0, 1], [0, 2]])\n",
    "    \n",
    "    ### folder or file name when saving the result\n",
    "    main_results_dir = \"../results\",\n",
    "    data_name = data_select, # Please rewrite this name if users want to use their own data.\n",
    "    \n",
    "    # In the default setting, The optimization results are saved in the folder named \"data_name\" + \"representation.name_vs_representation.name\". \n",
    "    # If you want to change the name of the saved folder, please make changes these three list below.\n",
    "    results_dir_list = None,\n",
    "    pair_name_list = None,\n",
    "    file_name_list = None,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisualizationConfig\n",
    "You can set the parameters for the visualization of the matrices, the embeddings and/or evaluation figures after the alignment was done.\n",
    "\n",
    "Here, we aim to introduce all the parameters that will be used for this instance, keeping in mind that some of them may be modified later for each dataset.\n",
    "\n",
    "Please keep in mind you can also get the raw results data if you want to make the figures by yourself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_config = VisualizationConfig(\n",
    "    ### If you want to save the figure only, and don't show them, please set show_figure = False.\n",
    "    show_figure = True,\n",
    "    \n",
    "    ### Please set the parameters below that can be used in \"matplotlib.pyplot\"\n",
    "    figsize=(8, 6),\n",
    "    cbar_ticks_size=15,\n",
    "    ticks_size=20,\n",
    "    xticks_rotation=90,\n",
    "    yticks_rotation=0,\n",
    "    title_size=20,\n",
    "    legend_size=5,\n",
    "    xlabel=None,\n",
    "    xlabel_size=15,\n",
    "    ylabel=None,\n",
    "    ylabel_size=15,\n",
    "    zlabel=None,\n",
    "    zlabel_size=15,\n",
    "    color_labels=None,\n",
    "    color_hue=None,\n",
    "    markers_list=None,\n",
    "    marker_size=30,\n",
    "    color = 'C0',\n",
    "    cmap = 'cividis',\n",
    "    \n",
    "    ### Set ticks of the object label or the coarce category labels.\n",
    "    # If both are False, no tick will be shown in the figure.\n",
    "    ot_object_tick=False,\n",
    "    ot_category_tick=False,\n",
    "    \n",
    "    ### Set the parameters for showing the boundary of the coarce category labels in the OT figure if the dataset have them. \n",
    "    # If not, please set draw_category_line = False.\n",
    "    # Note that please set ot_category_tick = True when drawing the category line.\n",
    "    \n",
    "    draw_category_line=False,\n",
    "    category_line_color='C2',\n",
    "    category_line_alpha=0.2,\n",
    "    category_line_style='dashed',\n",
    "    \n",
    "    \n",
    "    ### From here below, user can define the parameters using for evaluation figure after alignment computation is done.\n",
    "    # It is not necessary to set them here becuase we prepared \"set_params\" to add or re-define the parameters for making the figures. \n",
    "    # So, all the parameters below will be introduced after the alignment block.\n",
    "    plot_eps_log=False,\n",
    "    lim_eps=None,\n",
    "    lim_gwd=None,\n",
    "    lim_acc=None,  \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show dissimilarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset No.1 : color \n",
    "if data_select == \"color\":\n",
    "    sim_mat_format = \"default\"\n",
    "    \n",
    "    visualize_config = VisualizationConfig(\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        ot_object_tick=True\n",
    "    )\n",
    "    \n",
    "    visualize_hist = VisualizationConfig(figsize=(8, 6), color='C0')\n",
    "    \n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format = sim_mat_format, \n",
    "        visualization_config = visualize_config,\n",
    "        visualization_config_hist = visualize_hist,\n",
    "        show_distribution=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset No.2 : THINGS\n",
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "    visualize_config = VisualizationConfig(\n",
    "        show_figure = True,\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        cmap = 'Blues',\n",
    "        cbar_ticks_size=20,\n",
    "        \n",
    "        ot_object_tick=False,\n",
    "        ot_category_tick=True,\n",
    "        \n",
    "        # Note that please set ot_category_tick = True when drawing the category line.\n",
    "        draw_category_line=True,\n",
    "        category_line_color='C4',\n",
    "        category_line_alpha=0.5,\n",
    "        category_line_style='dashed',\n",
    "       \n",
    "    )\n",
    "    \n",
    "    visualize_hist = VisualizationConfig(figsize=(8, 6), color='C0')\n",
    "    \n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format=sim_mat_format, \n",
    "        visualization_config=visualize_config,\n",
    "        visualization_config_hist=visualize_hist,\n",
    "        fig_dir=None,\n",
    "        show_distribution=False,\n",
    "        ticks='category'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset No.3 : DNN\n",
    "if data_select == \"DNN\":\n",
    "    sim_mat_format = \"default\"\n",
    "    \n",
    "    visualize_config = VisualizationConfig(\n",
    "        show_figure = True,\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        cmap = 'Blues',\n",
    "        cbar_ticks_size=20,\n",
    "        ot_object_tick=True,   \n",
    "    )\n",
    "    \n",
    "    visualize_hist = VisualizationConfig(figsize=(8, 6), color='C0')\n",
    "    \n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format=sim_mat_format, \n",
    "        visualization_config=visualize_config,\n",
    "        visualization_config_hist=visualize_hist,\n",
    "        fig_dir=None,\n",
    "        show_distribution=False,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reperesentation Similarity Aanalysis (RSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for computing RSA\n",
    "# metric = \"pearson\" or \"spearman\" by scipy.stats\n",
    "# method = \"normal\" or \"all\"\n",
    "#     \"normal\" : perform RSA with the upper-triangle matrix of sim_mat\n",
    "#     \"all\" : perform RSA with the full matrix of sim_mat\n",
    "align_representation.RSA_get_corr(metric = \"pearson\", method = 'all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform GW Alignment\n",
    "The optimization results are saved in the folder named \"config.data_name\" + \"representations.name\" vs \"representation.name\".  \n",
    "If you want to change the name of the saved folder, please make changes to \"config.data_name\" and \"representations.name\" (or change the \"filename\" in the code block below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the computation has been completed and there is no need to recompute, set \"compute_OT\" to False. In this case, the previously calculated OT plans will be loaded.\n",
    "# If users want to compare both numpy and torch, \"compute_OT\" needs to be True (e.g. an expected case is that users wants to change the \"to_types\" once after the computation is finished)\n",
    "compute_OT = False\n",
    "\n",
    "### If the previous optimization data exists, you can delete it.\n",
    "# If you are attempting the same optimization with a different epsilon search space (eps_list), it is recommended to delete the previous results.\n",
    "# Setting delete_results=True will delete both the database and the directory where the results of the previous optimization are stored.\n",
    "# This function only works when n_job = 1, all the computed results exist, and \"compute_OT\" is set to False.\n",
    "# The code will prompt for confirmation before deleting all the results.\n",
    "delete_results = False\n",
    "\n",
    "### If user wants to specify a different eps range in some certain pairs, you can make an dict of eps list for them. Other pairs will use the range defined in \"config\".\n",
    "# If there is no pair to have their specific eps range, please set the pair_eps_range = {} or None. Then, the eps range which user defined in \"config\" will be used for each pair.\n",
    "# example : pair_eps_list = {\"Group1_vs_Group2\":[10, 100]} -> the pair named \"Group1_vs_Group2\" will use the eps range ([10, 100]). eps_log in \"config\" will be applied\n",
    "# caucation!! : please use \"_vs_\" between the representations' names.\n",
    "pair_eps_list = None #{\"Group1_vs_Group2\":[5, 20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\" # \"sorted\" : the rows and columns of the OT plans are sorted by the coarce categories. If there is no need for sorting, set it to \"default\".\n",
    "    \n",
    "    visualize_config.set_params(\n",
    "        # user can re-define the parameter if necessary.\n",
    "        show_figure=True,  \n",
    "        cmap = 'viridis',\n",
    "        category_line_color='black',\n",
    "        category_line_alpha=0.2,\n",
    "    )\n",
    "\n",
    "    ot_list = align_representation.gw_alignment(\n",
    "        pair_eps_list = pair_eps_list,\n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        \n",
    "        ## return_data : If True, the \"OT_format\" data will be returned in `ot_list`.\n",
    "        return_data = False,\n",
    "        \n",
    "        ## return_figure : If True, figure of OT will be made.\n",
    "        return_figure = True,\n",
    "        \n",
    "        OT_format = sim_mat_format,\n",
    "        visualization_config = visualize_config,\n",
    "        \n",
    "        ## show_log : if True, this will show the figures how the GWD was optimized. \n",
    "        # So, please set the parameters of them before this function starts to compute.\n",
    "        # The details of it will be explained in the next block.\n",
    "        show_log=False, \n",
    "        \n",
    "        ## fig_dir : you can define the path to which you save the figures (.png). If None, the figures will be saved in the same subfolder in \"results_dir\"\n",
    "        fig_dir=None,\n",
    "        \n",
    "        ## ticks : you can use \"objects\" or \"category\" or \"None\"\n",
    "        ticks='category', \n",
    "        \n",
    "        save_dataframe=False,\n",
    "        \n",
    "        ## change_sampler_seed : If True, the random seed will be changed for each pair, else, the same seed defined in the next parameter will be used.  Default is False.\n",
    "        change_sampler_seed=True, \n",
    "        \n",
    "        ## fix_sampler_seed : this seed is used mainly for random sampler and TPE samapler. you can set any int (>= 0) value for sampler's seed. Default is 42.\n",
    "        fix_sampler_seed = 42, \n",
    "        \n",
    "        ## parallel_method : user can change the way of parallel computation, \"multiprocess\" or \"multithread\".\n",
    "        # \"multithread\" may be effective for most case, please choose the best one for user's environment.\n",
    "        parallel_method=\"multithread\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"color\":\n",
    "    visualize_config = VisualizationConfig(\n",
    "        show_figure=True,\n",
    "        figsize=(10, 10), \n",
    "        title_size = 15, \n",
    "        ot_object_tick=True,\n",
    "    )\n",
    "\n",
    "    align_representation.gw_alignment(\n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        return_data = False,\n",
    "        return_figure = False,\n",
    "        OT_format = sim_mat_format, # \"default\"\n",
    "        visualization_config = visualize_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"DNN\":\n",
    "    visualize_config = VisualizationConfig(\n",
    "        show_figure=True,\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        ot_object_tick=True,\n",
    "    )\n",
    "\n",
    "    align_representation.gw_alignment(\n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        return_data = False,\n",
    "        return_figure = False,\n",
    "        OT_format = sim_mat_format, # \"default\"\n",
    "        visualization_config = visualize_config,\n",
    "        show_log=True, \n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show how the GWD was optimized\n",
    "`show_optimization_log` will make two figures to show both the relationships between epsilons (x-axis) and GWD (y-axis), and between accuracy (x-axis) and GWD (y-axis).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### user can define the parameters using for evaluation figure after alignment computation is done.\n",
    "if data_select == \"THINGS\":\n",
    "    visualize_config.set_params(\n",
    "        # user can re-define the parameter if necessary.\n",
    "        show_figure=False, \n",
    "        cmap = 'viridis',\n",
    "        \n",
    "        # plot_eps_log : user can choose the scale of eps in the figure. True = log scale, False = linear scale.\n",
    "        plot_eps_log=False,\n",
    "        \n",
    "        # lim_eps : define the range of eps to show in the figure. \n",
    "        # If None, default setting of matplotlib to detect the range will be used.\n",
    "        lim_eps=None,\n",
    "        \n",
    "        # lim_gwd : define the range of GWD to show in the figure. \n",
    "        # If None, default setting of matplotlib to detect the range will be used.\n",
    "        lim_gwd=None,\n",
    "        \n",
    "        # lim_acc : define the range of accuracy to show in the figure. the unit of accuracy is percentage. So, maximum is 100.\n",
    "        # If None, default setting of matplotlib to detect the range will be used.\n",
    "        lim_acc=[0, 100],      \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show how the GWD was optimized (evaluation figure)\n",
    "# show both the relationships between epsilons and GWD, and between accuracy and GWD\n",
    "align_representation.show_optimization_log(\n",
    "    fig_dir=None,\n",
    "    visualization_config=visualize_config,\n",
    ") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the accuracy of the unsupervised alignment\n",
    "There are two ways to evaluate the accuracy.  \n",
    "1. Calculate the accuracy based on the OT plan. \n",
    "- For using this method, please set the parameter `eval_type = \"ot_plan\"` in \"calc_accuracy()\".\n",
    "  \n",
    "2. Calculate the matching rate based on the k-nearest neighbors of the embeddings.\n",
    "-  For using this method, please set the parameter `eval_type = \"k_nearest\"` in \"calc_accuracy()\".\n",
    "\n",
    "For both cases, the accuracy evaluation criterion can be adjusted by considering \"top k\".  \n",
    "By setting \"top_k_list\", you can observe how the accuracy increases as the criterion is relaxed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the accuracy based on the OT plan. \n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"ot_plan\")\n",
    "align_representation.plot_accuracy(eval_type = \"ot_plan\", scatter = True)\n",
    "\n",
    "top_k_accuracy = align_representation.top_k_accuracy # you can get the dataframe directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the matching rate based on the k-nearest neighbors of the embeddings.\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"k_nearest\")\n",
    "align_representation.plot_accuracy(eval_type = \"k_nearest\", scatter = True)\n",
    "\n",
    "k_nearest_matching_rate = align_representation.k_nearest_matching_rate # you can get the dataframe directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calclate the category level accuracy\n",
    "\n",
    "# If the data has the coarse category labels, you can observe the category level accuracy.\n",
    "# This accuracy is calculated based on the OT plan.\n",
    "if data_select == \"THINGS\":\n",
    "    align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"category\", category_mat=category_mat)\n",
    "    align_representation.plot_accuracy(eval_type = \"category\", scatter = True)\n",
    "\n",
    "    category_level_accuracy = align_representation.category_level_accuracy # you can get the dataframe directly "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the aligned embeddings\n",
    "Using optimized transportation plans, you can align the embeddings of each representation to a shared space in an unsupervised manner.  \n",
    "The `\"pivot\"` refers to the target embeddings space to which the other embeddings will be aligned.   \n",
    "You have the option to designate the `\"pivot\"` as one of the representations or the barycenter.  \n",
    "Please ensure that 'pair_number_list' includes all pairs between the pivot and the other Representations.  \n",
    "\n",
    "If you wish to utilize the barycenter, please make use of the method `AlignRepresentation.barycenter_alignment()`.  \n",
    "You can use it in the same manner as you did with `AlignRepresentation.gw_alignment()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color labels and coarse category labels if exist.\n",
    "# If there are a large number of objects within each group, such as in the case of THINGS data, visualizing all the points may not be meaningful. \n",
    "# In such cases, it is necessary to specify specific coarse category labels that you would like to visualize.\n",
    "if data_select == \"THINGS\":\n",
    "    category_name_list = [\"bird\", \"insect\", \"plant\", \"clothing\",  \"furniture\", \"fruit\", \"drink\", \"vehicle\"] # please specify the categories that you would like to visualize.\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)   \n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat, category_name_list, show_numbers = True)  \n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        figsize=(8, 8), \n",
    "        xlabel=\"PC1\",\n",
    "        ylabel=\"PC2\", \n",
    "        zlabel=\"PC3\", \n",
    "        marker_size=6,\n",
    "        legend_size=10\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3,  # the dimensionality of the space the points are embedded in. You can choose either 2 or 3.\n",
    "        pivot=0, # the number of one of the representations or the \"barycenter\".\n",
    "        visualization_config=visualization_embedding,\n",
    "        category_name_list=category_name_list, \n",
    "        category_idx_list=category_idx_list, \n",
    "        num_category_list=num_category_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == 'color':\n",
    "    file_path = \"../data/color_dict.csv\"\n",
    "    data_color = pd.read_csv(file_path)\n",
    "    color_labels = data_color.columns.values # Set color labels if exist\n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        color_labels=color_labels, # If there is no specific color labels, please set it to \"None\". Color labels will be automatically generated in that case. \n",
    "        color_hue=None, # If \"color_labels=None\", you have the option to choose the color hue as either \"cool\", \"warm\", or \"None\".\n",
    "        figsize=(9, 9), \n",
    "        xlabel=\"PC1\", \n",
    "        ylabel=\"PC2\",\n",
    "        zlabel=\"PC3\", \n",
    "        legend_size=10\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3, # the dimensionality of the space the points are embedded in. You can choose either 2 or 3.\n",
    "        pivot=0, # the number of one of the representations or the \"barycenter\".\n",
    "        visualization_config=visualization_embedding\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Delete Results\n",
    "\n",
    "If you want to delete both the directory and the database where the calculation results are stored all at once, you can use drop_gw_alignment_files.  \n",
    "Please be very careful because this operation is irreversible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align_representation.drop_gw_alignment_files(drop_all=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
