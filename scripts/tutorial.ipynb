{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tutorial for using `align_represenatations.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from src.align_representations import Representation, AlignRepresentations, OptimizationConfig, VisualizationConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load data\n",
    " you can choose the following data\n",
    " 1. 'DNN': representations of 2000 imagenet images in AlexNet and VGG19\n",
    " 1. 'color': human similarity judgements of 93 colors for 5 paricipants groups\n",
    " 1. 'face': human similarity judgements of 16 faces, attended vs unattended condition in the same participant\n",
    " 1. 'THINGS' : human similarity judgements of 1854 objects for 4 paricipants groups\n",
    "\n",
    "\n",
    " \"data_select\" in next code block can define which dataset are going to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = \"THINGS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Representations\n",
    "#   - A Representation needs a name and either an embedding or a similarity matrix.\n",
    "\n",
    "# representations list that will be used in Align_Representations\n",
    "representations = list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Dataset No1. `color`\n",
    " This dataset doesn't have label information for each one of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create representations instance\n",
    "if data_select == 'color':\n",
    "    n_representations = 5 # Set the number of representations. This number must be equal to or less than the number of groups.\n",
    "    metric = \"euclidean\" # Please set metric that can be used in \"scipy.distance.cdist()\"\n",
    "    \n",
    "    # If dataset doesn't have label info, please set the categpry_mat (and other parameters) = None.\n",
    "    category_mat = None\n",
    "    \n",
    "    data_path = '../data/num_groups_5_seed_0_fill_val_3.5.pickle'\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    sim_mat_list = data[\"group_ave_mat\"]\n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\"\n",
    "        sim_mat = sim_mat_list[i]\n",
    "        representation = Representation(name = name, sim_mat = sim_mat)\n",
    "        representations.append(representation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Dataset No.2 `THINGS`\n",
    " This dataset has label information. So we demonstrate how to define it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    # define the label information of the dataset\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)\n",
    "    \n",
    "    # define the parameters for label info. \n",
    "    # Users can define these by themselves if they use a different dataset and the format of parameters are the same.\n",
    "    from src.utils.utils_functions import get_category_data, sort_matrix_with_categories\n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat)\n",
    "    \n",
    "    n_representations = 4 # Set the number of representations. This number must be equal to or less than the number of groups.\n",
    "    metric = \"euclidean\" # Please set metric that can be used in \"scipy.distance.cdist()\"\n",
    "    \n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\"\n",
    "        embedding = np.load(f\"../data/THINGS_embedding_Group{i+1}.npy\")[0]\n",
    "        \n",
    "        representation = Representation(\n",
    "            name = name, \n",
    "            embedding = embedding, \n",
    "            metric = metric, \n",
    "            object_labels = object_labels,\n",
    "            category_name_list = category_name_list,\n",
    "            category_idx_list = category_idx_list,\n",
    "            num_category_list = num_category_list,\n",
    "            func_for_sort_sim_mat = sort_matrix_with_categories\n",
    "        )\n",
    "        \n",
    "        representations.append(representation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Set the parameters for the optimazation of GWOT, and the parameters for visualizing matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OptimizationConfig(\n",
    "    ### Set the range of epsilon\n",
    "    # set only the minimum value and maximum value for 'tpe' sampler\n",
    "    # for 'grid' or 'random' sampler, you can also set the step size\n",
    "    eps_list = [1, 10], # [1, 10] for THINGS data, [0.02, 0.2] for colors data\n",
    "    eps_log = True,\n",
    "    num_trial = 4, # set the number of trials, i.e., the number of epsilon values tested in optimization: default : 20\n",
    "    \n",
    "    ### Set the device ('cuda' or 'cpu') and variable type ('torch' or 'numpy')\n",
    "    to_types = 'torch', # user can choose \"numpy\" or \"torch\". please set \"torch\" if one wants to use GPU.\n",
    "    device = 'cuda', # \"cuda\" or \"cpu\"; for numpy, only \"cpu\" can be used. \n",
    "    \n",
    "    ### Parallel Computation (requires n_jobs > 1, both for numpy and torch)\n",
    "    n_jobs = 1, # n_jobs : the number of worker to compute. if n_jobs = 1, normal computation will start. \n",
    "    parallel_method = \"multithread\", # \"multiprocess\" or \"multithread\". Default is \"multithread\".\n",
    "    multi_gpu = [1,2], # This parameter is only for \"torch\". # \"True\" : all the GPU installed in your environment, \"list (e.g.[0,2,3])\"\" : cuda:0,2,3, and \"False\" : single gpu (or cpu for numpy) will use.\n",
    "    \n",
    "    ### Set the database URL to store the optimization results (either PyMySQL or SQLite. For using PyMySQL, some additional setting beforehand will be needed).  \n",
    "    # To use remote databases, you need to start the database server beforehand. For detailed instruction, please refer to the Optuna official tutorial:  \n",
    "    # https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html  \n",
    "    \n",
    "    storage = None, # When using SQLite, the database file is automatically created, so you only need to set None.\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # 1. initialization of transportation plan\n",
    "    # 2. 'uniform': uniform matrix, 'diag': diagonal matrix\n",
    "    # 3. 'random': random matrix, 'permutation': permutation matrix\n",
    "    # you can select multiple options (e.g. init_plans_list = ['uniform', 'random'])\n",
    "    init_plans_list = ['random'],\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # n_iter : the number of random initial matrices for 'random' or 'permutation' options：default: 100\n",
    "    # max_iter : the maximum number of iteration for GW optimization: default: 1000\n",
    "    n_iter = 1,\n",
    "    max_iter = 200,\n",
    "    \n",
    "    ### folder or file name when saving the result\n",
    "    # Optimization results are saved in the folder by \"config.data_name\" + \"representations.name\" vs \"representation.name\".\n",
    "    # If you want to change the name of the saved folder, please change \"config.data_name\" and \"representations.name\".\n",
    "    data_name = data_select, \n",
    "    \n",
    "    ### user can delete the result data if existed and they want.  \n",
    "    # Delete previous optimization results or not  \n",
    "    # If the same filename has different search space, optuna may not work well.\n",
    "    delete_study = False, \n",
    "    \n",
    "    ### choose sampler implemented by Optuna\n",
    "    # 1. 'random': randomly select epsilon between the range of epsilon\n",
    "    # 2. 'grid': grid search between the range of epsilon\n",
    "    # 3. 'tpe': Bayesian sampling\n",
    "    sampler_name = 'tpe',\n",
    "    \n",
    "    ### choose pruner\n",
    "    # 1. 'median': Pruning if the score is below the past median at a certain point in time  \n",
    "    #     n_startup_trials: Do not activate the pruner until this number of trials has finished  \n",
    "    #     n_warmup_steps: Do not activate the pruner for each trial below this step  \n",
    "        \n",
    "    # 2. 'hyperband': Use multiple SuccessiveHalvingPrunerd that gradually longer pruning decision periods and that gradually stricter criteria  \n",
    "    #     min_resource: Do not activate the pruner for each trial below this step  \n",
    "    #     reduction_factor: How often to check for pruning. Smaller values result in more frequent pruning checks. Between 2 to 6.  \n",
    "        \n",
    "    # 3. 'nop': no pruning\n",
    "    pruner_name = 'hyperband',\n",
    "    pruner_params = {'n_startup_trials': 1, \n",
    "                     'n_warmup_steps': 2, \n",
    "                     'min_resource': 2, \n",
    "                     'reduction_factor' : 3\n",
    "                    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisualizationConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix = VisualizationConfig(\n",
    "    ### Please set the parameters below that can be used in \"mttplotlib.pyplot\"\n",
    "    figsize=(8, 6), \n",
    "    title_size = 15, \n",
    "    cmap = 'cividis',\n",
    "    cbar_ticks_size=20,\n",
    "    ticks_size=5,\n",
    "    xticks_rotation=90,\n",
    "    yticks_rotation=0,\n",
    "    legend_size=5,\n",
    "    xlabel=None,\n",
    "    xlabel_size=15,\n",
    "    ylabel=None,\n",
    "    ylabel_size=15,\n",
    "    zlabel=None,\n",
    "    zlabel_size=15,\n",
    "    color_labels=None,\n",
    "    color_hue=None,\n",
    "    markers_list=None,\n",
    "    marker_size=30,\n",
    "    \n",
    "    ### Set the parameters for showing the boundary of category or label info if the dataset have. If not, please draw_category_line = False.\n",
    "    draw_category_line=True,\n",
    "    category_line_color='C2',\n",
    "    category_line_alpha=0.2,\n",
    "    category_line_style='dashed',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Unsupervised alignment between Representations\n",
    "     - The object has methods for RSA, histogram matching, GW-alignment, evaluation of the alignment and visalization of aligned embeddings.\n",
    "     - If you want to limit the pairs that are applied GW alignment, please set “AlignRepresentations.pair_number_list”. (e.g. pair_number_list = [[0, 1], [0, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the instance\n",
    "align_representation = AlignRepresentations(\n",
    "    representations_list=representations,\n",
    "    pair_number_list='all', #If you want to limit the pairs that are applied GW alignment, please set “AlignRepresentations.pair_number_list”. (e.g. pair_number_list = [[0, 1], [0, 2]])\n",
    "    histogram_matching=False,\n",
    "    config=config,\n",
    "    metric=\"cosine\",\n",
    ")\n",
    "\n",
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "    visualize_matrix = VisualizationConfig(\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        cmap = 'Blues',\n",
    "        cbar_ticks_size=20,\n",
    "        \n",
    "        draw_category_line=True,\n",
    "        category_line_color='C4',\n",
    "        category_line_alpha=0.5,\n",
    "        category_line_style='dashed',\n",
    "       \n",
    "        )\n",
    "    \n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format=sim_mat_format, \n",
    "        visualization_config=visualize_matrix,\n",
    "        fig_dir=None,\n",
    "        show_distribution=False,\n",
    "        ticks='category'\n",
    "    )\n",
    "\n",
    "if data_select == \"color\":\n",
    "    sim_mat_format = \"default\"\n",
    "    visualize_matrix = VisualizationConfig(figsize=(8, 6), title_size = 15)\n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format = sim_mat_format, \n",
    "        visualization_config = visualize_matrix,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### arguments for computing RSA\n",
    "# metric = \"pearson\" or \"spearman\" by scipy.stats\n",
    "# method = \"normal\" or \"all\"\n",
    "#     \"normal\" : the data to take the RSA is the upper-triangle of sim_mat (numpy.triu_indices(sim_mat.shpe[0], k=1)).\n",
    "#     \"all\" : the data to take the RSA is all the values of dis-similarity matrix (sim_mat.flatten()).\n",
    "align_representation.RSA_get_corr(metric = \"pearson\", method = 'all')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Computing GW Alignment.\n",
    " Optimization results are saved in the folder by \"config.data_name\" + \"representations.name\" vs \"representation.name\".  \n",
    " If you want to change the name of the saved folder, please change \"config.data_name\" and \"representations.name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "    visualize_matrix = VisualizationConfig(figsize=(8, 6), title_size = 15, category_line_color = 'C1')\n",
    "\n",
    "    ot_list = align_representation.gw_alignment(\n",
    "        results_dir = \"../results\",\n",
    "        compute_OT = False,  # If the computation was done and no need for, turn \"compute_OT\" False, then OT plans calculated before is loaded.\n",
    "        return_data = False, # If True, the data will be stored in `ot_list`.\n",
    "        return_figure = True,\n",
    "        OT_format = sim_mat_format, # \"default\", \"sorted\" or \"both\" (= \"default\" and \"sorted\").\n",
    "        visualization_config = visualize_matrix,\n",
    "        show_log=False, # if True, this will show the figures how the GWD was optimized.\n",
    "        fig_dir=None, # you can define the path to save the figures (.png). If None, the figures will be saved in the same subfolder in \"results_dir\"\n",
    "        ticks = 'category', # you can use \"objects\" or \"category\" or \"None\"\n",
    "    )\n",
    "\n",
    "if data_select == \"color\":\n",
    "    visualize_matrix = VisualizationConfig(figsize=(10, 10), title_size = 15)\n",
    "\n",
    "    align_representation.gw_alignment(\n",
    "        results_dir = \"../results\",\n",
    "        compute_OT = False,\n",
    "        return_data = False,\n",
    "        return_figure = True,\n",
    "        OT_format = sim_mat_format, # \"default\"\n",
    "        visualization_config = visualize_matrix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show how the GWD was optimized\n",
    "align_representation.show_optimization_log(results_dir=\"../results\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Align embeddings with OT plans and Visualize the aligned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the accuracy of the optimized OT matrix\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"ot_plan\")\n",
    "align_representation.plot_accuracy(eval_type = \"ot_plan\", scatter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the matching rate of k-nearest neighbors of embeddings\n",
    "## Matching rate of k-nearest neighbors \n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"k_nearest\")\n",
    "align_representation.plot_accuracy(eval_type = \"k_nearest\", scatter = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## category level analysis\n",
    " User can use this analysis if the dataset has category info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calclate the category level accuracy\n",
    "if data_select == \"THINGS\":\n",
    "    align_representation.calc_category_level_accuracy(category_mat=category_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color labels and category data if exist.\n",
    "if data_select == \"THINGS\":\n",
    "    category_name_list = [\"bird\", \"insect\", \"plant\", \"clothing\",  \"furniture\", \"fruit\", \"drink\", \"vehicle\"]\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)   \n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat, category_name_list, show_numbers = True)  \n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        figsize=(15, 15), \n",
    "        xlabel=\"PC1\",\n",
    "        ylabel=\"PC2\", \n",
    "        zlabel=\"PC3\", \n",
    "        marker_size=20,\n",
    "        legend_size=10\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3,  \n",
    "        visualization_config=visualization_embedding,\n",
    "        category_name_list=category_name_list, \n",
    "        category_idx_list=category_idx_list, \n",
    "        num_category_list=num_category_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == 'color':\n",
    "    file_path = \"../data/color_dict.csv\"\n",
    "    data_color = pd.read_csv(file_path)\n",
    "    color_labels = data_color.columns.values\n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        color_labels=color_labels, \n",
    "        figsize=(15, 15), \n",
    "        xlabel=\"PC1\", \n",
    "        ylabel=\"PC2\",\n",
    "        zlabel=\"PC3\", \n",
    "        legend_size=10\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3, \n",
    "        visualization_config=visualization_embedding\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
