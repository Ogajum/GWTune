{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tutorial for Gromov-Wassserstein unsupervised alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from src.align_representations import Representation, AlignRepresentations, OptimizationConfig\n",
    "from src import visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Prepare dissimilarity matrices or embeddings from the data\n",
    "First, you need to prepare dissimilarity matrices or embeddings from your data.  \n",
    "To store dissimilarity matrices or embeddings, an instance of the class `Representation` is used.   \n",
    "Please put your dissimilarity matrices or embeddings into the variables `sim_mat` or `embedding` in this instance.   \n",
    "\n",
    "## Load data\n",
    "You can select the data from the following options:   \n",
    "1. `color`: Human similarity judgements of 93 colors for 5 groups of participants from the data used in Kawakita et al., 2023, PsyArxiv   \n",
    "2. `THINGS` : Human similarity judgments of 1854 objects for 4 groups of participants from the THINGS data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of representations where the instances of \"Representation\" class are included\n",
    "representations = list()\n",
    "\n",
    "# select data : \"THINGS\", \"color\"\n",
    "data_select = \"color\"\n",
    "# data_select = \"THINGS\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No.1 `color`\n",
    "In this case, we directly assign the dissimilarity matrices of 93 colors to the instance `Representation`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create \"Representation\" instance\n",
    "if data_select == 'color':\n",
    "    n_representations = 4 # Set the number of the instanses of \"Representation\". This number must be equal to or less than the number of the groups. 5 is the maximum for this data.\n",
    "    metric = \"euclidean\" # Please set the metric that can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    \n",
    "    data_path = '../data/color/num_groups_5_seed_0_fill_val_3.5.pickle'\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    sim_mat_list = data[\"group_ave_mat\"]\n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\" # \"name\" will be used as a filename for saving the results\n",
    "        sim_mat = sim_mat_list[i] # the dissimilarity matrix of the i-th group\n",
    "        # make an instance \"Representation\" with settings \n",
    "        representation = Representation(\n",
    "            name=name, \n",
    "            metric=metric,\n",
    "            sim_mat=sim_mat,  #: np.ndarray\n",
    "            embedding=None,   #: np.ndarray \n",
    "            get_embedding=True, # If true, the embeddings are computed from the dissimilarity matrix automatically using the MDS function. Default is False. \n",
    "            MDS_dim=3, # If \"get embedding\" is True, please set the dimensions of the embeddings.\n",
    "            object_labels=None,\n",
    "            category_name_list=None,\n",
    "            num_category_list=None,\n",
    "            category_idx_list=None,\n",
    "            func_for_sort_sim_mat=None,\n",
    "       ) \n",
    "        representations.append(representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No.2 `THINGS`\n",
    "In this case, we assign the embeddings of 1854 natural objects to the instance `Representation`.   \n",
    "This instance compute the dissimilarity matrices from the embeddings based on `metric`.  \n",
    "\n",
    "In addition to the object labels, this dataset includes coarse category labels for each object.   \n",
    "These coarse category labels are used for the evaluation and visualization of alignment.  \n",
    "The category information is stored in the variables `category_idx_list` and `category_name_list`.  \n",
    "For your application, please put category information in these variables.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    # define the coarce category labels\n",
    "    category_mat = pd.read_csv(\"../data/THINGS/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)\n",
    "    \n",
    "    # calculate the parameters for the coarce category labels\n",
    "    # Please prepare equivalent parameters when using other datasets.\n",
    "    from src.utils.utils_functions import get_category_data, sort_matrix_with_categories # get_category_data and sort_matrix_with_categories are functions specialied for this dataset\n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat)\n",
    "    \n",
    "    n_representations = 3 # Set the number of the instanses of \"Representation\". This number must be equal to or less than the number of the groups. 4 is the maximum for this data.\n",
    "    metric = \"euclidean\" # Please set the metric that can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    \n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\" # the name of the representation\n",
    "        embedding = np.load(f\"../data/THINGS/THINGS_embedding_Group{i+1}.npy\")[0] # the dissimilarity matrix will be computed with this embedding based on the metric\n",
    "        \n",
    "        representation = Representation(\n",
    "            name=name,\n",
    "            embedding=embedding,\n",
    "            metric=metric,\n",
    "            get_embedding=False, # If there is the embeddings, plese set this variable \"False\".\n",
    "            object_labels=object_labels, # the labels of the objects\n",
    "            category_name_list=category_name_list, # the names of the categories\n",
    "            category_idx_list=category_idx_list, # the indexes of the categories. This is used for the evaluation and the visualization of the unsuperivsed alignment.\n",
    "            num_category_list=num_category_list, \n",
    "            func_for_sort_sim_mat=sort_matrix_with_categories,\n",
    "        )\n",
    "        \n",
    "        representations.append(representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Set the parameters for the optimazation of GWOT\n",
    "Second, you need to set the parameters for the optimization of GWOT.    \n",
    "For most of the parameters, you can start with the default values.   \n",
    "However, there are some essential parameters that you need to check for your original applications.  \n",
    "\n",
    "## Optimization Config  \n",
    "\n",
    "#### Most important parameters to check for your application:\n",
    "`eps_list`: The range of the values of epsilon for entropic GWOT.   \n",
    "If epsilon is not in appropriate ranges (if it is too low), the optimization may not work properly.   \n",
    "Although the algorithm will find good epsilon values after many trials, it is a good practice to narrow down the range beforehand.   \n",
    "\n",
    "`num_trial`: The number of trials to test epsilon values from the specified range.   \n",
    "This number directly determines the quality of the unsupervised alignment.   \n",
    "You should set this number high enough to find good local minima.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Most important parameters\n",
    "# Set the range of the epsilon\n",
    "# set the minimum value and maximum value for 'tpe' sampler\n",
    "# for 'grid' or 'random' sampler, you can also set the step size    \n",
    "if data_select == \"color\":\n",
    "    eps_list_tutorial = [0.02, 0.2]\n",
    "    device = 'cpu'\n",
    "    to_types = 'numpy'\n",
    "\n",
    "if data_select == \"THINGS\":\n",
    "    eps_list_tutorial = [1, 10]\n",
    "    device = 'cuda' # 'cuda'\n",
    "    to_types = 'torch' # 'torch'\n",
    "    \n",
    "# whether epsilon is sampled at log scale or not\n",
    "eps_log = True\n",
    "\n",
    "# set the number of trials, i.e., the number of epsilon values evaluated in optimization. default : 4\n",
    "num_trial = 4\n",
    "\n",
    "### Set the parameters for optimization\n",
    "# initialization of transportation plan\n",
    "# 'uniform': uniform matrix, 'diag': diagonal matrix', random': random matrix\n",
    "# Select multiple options was deprecated.\n",
    "init_mat_plan = \"random\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The setting of device (cuda or cpu)\n",
    "`cuda` : For using GPU, the `device` and `to_types` needs to be set to `cuda` and `torch`, respectively. You can choose to use multiple GPUs by setting `multi_gpu` to True.\n",
    "\n",
    "`cpu` : For using numpy, the device needs to be set to `cpu` and to_types needs to be set to `numpy`. The `multi_gpu` option is not available for numpy, so `multi_gpu = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == 'cuda':\n",
    "    sinkhorn_method = 'sinkhorn_log' # please choose the method of sinkhorn implemented by POT (URL : https://pythonot.github.io/gen_modules/ot.bregman.html#id87). For using GPU, \"sinkhorn_log\" is recommended.\n",
    "    data_type= 'float'\n",
    "    multi_gpu = False, # This parameter is only designed for \"torch\". # \"True\" : all the GPU installed in your environment are used, \"list (e.g.[0,2,3])\"\" : cuda:0,2,3, and \"False\" : single gpu will be used.\n",
    "\n",
    "elif device == 'cpu':\n",
    "    sinkhorn_method = 'sinkhorn'\n",
    "    data_type = 'double'\n",
    "    multi_gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If user wants to use some user-defined init matrices...\n",
    "For ”user_define”, note that all the initialization plans need to be written in Numpy even when PyTorch is used for the optimization.  \n",
    "You can define a single or multiple plans before the optimization starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if init_mat_plan == \"user_define\":\n",
    "    import ot\n",
    "    size = representation.sim_mat.shape[0]\n",
    "    user_define_init_mat_list = [np.outer(ot.unif(size), ot.unif(size))] # This is uniform tranportation plan but you can change it to any other plan\n",
    "else:\n",
    "    user_define_init_mat_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OptimizationConfig(  \n",
    "    ### Set the type of the Gromov-Wasserstein alignment.\n",
    "    # Options are \"entropic_gromov_wasserstein\", \"entropic_semirelaxed_gromov_wasserstein\" or \"entropic_partial_gromov_wasserstein\".\n",
    "    # For details on each alignment, please refer to POT (URL : https://pythonot.github.io/gen_modules/ot.gromov.html)\n",
    "    gw_type = \"entropic_gromov_wasserstein\",\n",
    "    \n",
    "    eps_list = eps_list_tutorial, # [1, 10] for THINGS data, [0.02, 0.2] for colors data\n",
    "    eps_log = eps_log, # whether epsilon is sampled at log scale or not\n",
    "    num_trial = num_trial, # set the number of trials, i.e., the number of epsilon values evaluated in optimization. default : 4\n",
    "    sinkhorn_method=sinkhorn_method, \n",
    "    \n",
    "    ### Set the device ('cuda' or 'cpu') and variable type ('torch' or 'numpy')\n",
    "    to_types = to_types, # user can choose \"numpy\" or \"torch\". please set \"torch\" if one wants to use GPU.\n",
    "    device = device, # \"cuda\" or \"cpu\"; for numpy, only \"cpu\" can be used. \n",
    "    data_type = data_type, # user can define the dtypes both for numpy and torch, \"float(=float32)\" or \"double(=float64)\". For using GPU with \"sinkhorn\", double is storongly recommended.\n",
    "    \n",
    "    ### Parallel Computation (requires n_jobs > 1, available both for numpy and torch)\n",
    "    n_jobs = 3, # n_jobs : the number of worker to compute. if n_jobs = 1, normal computation will start. \"Multithread\" is used for Parallel computation.\n",
    "    multi_gpu = multi_gpu,\n",
    "    \n",
    "    ### Set the storage (database URL) to save the optimization results (either PyMySQL or SQLite. For using PyMySQL, some additional setting beforehand will be needed). \n",
    "    # The database URL in sqlalchemy is like \"dialect+driver://username:password@host:port/database\". See the following page for details. https://docs.sqlalchemy.org/en/20/core/engines.html\n",
    "    # Set the `db_params` if you want to automatically generate 1 database per each study.\n",
    "    # If you want to use SQLite, it's enough to set \"db_params={\"drivername\": \"sqlite\"}\".\n",
    "    storage = None,\n",
    "    db_params = {\"drivername\": \"sqlite\"},\n",
    "    # db_params = {\"drivername\": \"mysql+pymysql\", \"username\": \"root\", \"password\": \"****\", \"host\": \"localhost\"},\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # 'uniform': uniform matrix, 'diag': diagonal matrix', random': random matrix\n",
    "    init_mat_plan = init_mat_plan,\n",
    "    \n",
    "    # user-defined initialization plans\n",
    "    user_define_init_mat_list = user_define_init_mat_list,\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # n_iter : the number of random initial matrices for 'random' or 'permutation' options：default: 1\n",
    "    # max_iter : the maximum number of iteration for GW optimization: default: 200\n",
    "    n_iter = 1,\n",
    "    max_iter = 200,\n",
    "    \n",
    "    ### choose sampler implemented by Optuna\n",
    "    # 1. 'random': randomly select epsilon between the range of epsilon\n",
    "    # 2. 'grid': grid search between the range of epsilon\n",
    "    # 3. 'tpe': Bayesian sampling\n",
    "    sampler_name = 'tpe',\n",
    "    \n",
    "    ### choose pruner\n",
    "    # 1. 'median': Pruning if the score is below the past median at a certain point in time  \n",
    "    #     n_startup_trials: Do not activate the pruner until this number of trials has finished  \n",
    "    #     n_warmup_steps: Do not activate the pruner for each trial below this step  \n",
    "        \n",
    "    # 2. 'hyperband': Use multiple SuccessiveHalvingPrunerd that gradually longer pruning decision periods and that gradually stricter criteria  \n",
    "    #     min_resource: Do not activate the pruner for each trial below this step  \n",
    "    #     reduction_factor: How often to check for pruning. Smaller values result in more frequent pruning checks. Between 2 to 6.  \n",
    "        \n",
    "    # 3. 'nop': no pruning\n",
    "    pruner_name = 'hyperband',\n",
    "    pruner_params = {'n_startup_trials': 1, \n",
    "                     'n_warmup_steps': 2, \n",
    "                     'min_resource': 2, \n",
    "                     'reduction_factor' : 3\n",
    "                    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Gromov-Wasserstein Optimal Transport (GWOT) between Representations\n",
    "Third, you perform GWOT between the instanses of \"Representation\", by using the class `AlignRepresentations`.  \n",
    "This class has methods for the optimization of entropic Gromov-Wasserstein distance, and the evaluation of the GWOT (Step 4).  \n",
    "This class also has a method to perform conventional Representation Similarity Analysis (RSA).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Directory for saving the results of GWOT\n",
    "\n",
    "Here is the directory structure to save the results below.  \n",
    "\n",
    "```\n",
    "    main_results_dir (= data_name (e.g. `THINGS`)) /\n",
    "        ├─ data_name + pair_name (e.g. `THINGS_Group1_vs_Group2`) /\n",
    "        │   ├─ initial_transportation_plan_name (e.g. `random`) /\n",
    "        │       ├─ figure /\n",
    "        │       │   ├─ some figures (e.g. acc_gwd_eps.png)\n",
    "        │       ├─ data /\n",
    "        │       │   ├─ OT.npy (numpy) or OT.pt (torch)\n",
    "        │       │   \n",
    "        │       ├─ database (if using sqlite; e.g. `THINGS_Group1_vs_Group2_random.db`)\n",
    "        │       ├─ study_info.json\n",
    "        │\n",
    "        ├─ individual_sim_mat (e.g. `RDM_Group1.png`) /\n",
    "        │   ├─ initial_transportation_plan_name (e.g. `random`) /\n",
    "        │       ├─  some figures(e.g. `RDM_Group1.png`) \n",
    "        │\n",
    "        ├─ individual_distribution (e.g. `distribution_Group1.png`) /\n",
    "        │  ├─ initial_transportation_plan_name (e.g. `random`) /\n",
    "        │       ├─  some figures(e.g. `distribution_Group1.png`) \n",
    "        │\n",
    "        ├─ visualize_embedding/ \n",
    "        │   ├─ initial_transportation_plan_name (e.g. `random`) /\n",
    "        │       ├─  some figures(e.g. `Aligned_embedding.png`; made by running `align_representation.visualize_embedding`.\n",
    "        │           Please see the bottom of this notebook) \n",
    "        │\n",
    "``` \n",
    "\n",
    "- This folder structure will be automatically made in the process of GWOT optimization.\n",
    "- You can provide the names of the save folders by changing the following variables: `main_result_dir`,  `data_name`, and `pair_name`(defined by the two `representations.name`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Choose pairs of representations for GWOT optimization\n",
    "By default, GWOT will be performed for all the pairs of given representations.   \n",
    "You can specify particular pairs that you want to compute as follows.   \n",
    "Also, you can also customize the epsilon range for particular pairs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default setting (compute all the pairs if `pair_computed` is None)\n",
    "pairs_computed = None\n",
    "\n",
    "# If you wish to compute only partiuclar pairs or all the pairs which have one partiuclar representation, you can specify them as follows.\n",
    "# In this example below,  \n",
    "# \"Group1\": all the pairs with \"Group1\"  \n",
    "# \"Group2_vs_Group4\": only the pair named \"Group2_vs_Group4\"\n",
    "# Please use \"_vs_\" between the representations' names for a single pair. \n",
    "# And please also keep in mind that the name of each pair will be made by the order of `representations_list`, which means \"Group4_vs_Group2\" can't be accepted.\n",
    "\n",
    "# pairs_computed = [\"Group1\", \"Group2_vs_Group4\"]\n",
    "\n",
    "# Default setting (use the same epsilon range for all the pairs)\n",
    "specific_eps_list = None\n",
    "\n",
    "# If you wish to change the epsilon range for particular pairs, you can specify them as follows.\n",
    "# specific_eps_list = {'Group1': [0.02, 0.1], \"Group2_vs_Group4\":[0.1, 0.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an \"AlignRepresentations\" instance\n",
    "align_representation = AlignRepresentations(\n",
    "    config=config,\n",
    "    representations_list=representations,   \n",
    "   \n",
    "    # pairs_computed : user can limit the pairs here\n",
    "    pairs_computed = pairs_computed,\n",
    "   \n",
    "    # specific_eps_list : user can define a specific range of epsilon for some pairs.\n",
    "    specific_eps_list = specific_eps_list,\n",
    "   \n",
    "    # histogram matching : this will adjust the histogram of target to that of source.\n",
    "    histogram_matching=False,\n",
    "\n",
    "    # metric : The metric for computing the distance between the embeddings. Please set the metric tha can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    metric=\"cosine\", \n",
    "\n",
    "    # main_results_dir : folder or file name when saving the result\n",
    "    main_results_dir = f\"../results/{data_select}\",\n",
    "   \n",
    "    # data_name : Please rewrite this name if users want to use their own data.\n",
    "    data_name = data_select,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When you want to re-run the optimization process for specific pairs only\n",
    "You can change the specific pairs to be computed by setting `pair_computed` as follows.   \n",
    "You can also change the epsilon range `specific_eps_list` as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User can only re-run the optimization for specific pairs by using `set_pair_computed`.\n",
    "\n",
    "# pairs_computed = [\"Group1\", \"Group2_vs_Group4\"]\n",
    "# align_representation.set_pair_computed(pairs_computed)\n",
    "\n",
    "# Also, user can also re-define the epsilon range for some pairs by using `set_specific_eps_list`. The rest of them will be computed with `config.eps_list`. \n",
    "# If `specific_only` is True (default is False), only these pairs will be computed and the rest of them were skipped.\n",
    "\n",
    "# specific_eps_list = {'Group1': [0.02, 0.1], \"Group2_vs_Group4\":[0.1, 0.2]}\n",
    "# align_representation.set_specific_eps_list(specific_eps_list, specific_only=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show dissimilarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset without category information\n",
    "if data_select == \"color\":\n",
    "    axes = visualization.show_sim_mat(\n",
    "        align_representation,\n",
    "        sim_mat_format=\"default\", \n",
    "        fig_dir=None,\n",
    "        ticks=None,\n",
    "        \n",
    "        # keyword arguments\n",
    "        show_figure = True,\n",
    "        fig_ext=\"svg\", # you can also use \"png\" or \"pdf\", and so on. Default is \"png\".\n",
    "        figsize=(6, 5), \n",
    "        title_size = 15, \n",
    "        cmap = 'rocket_r',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset with category information\n",
    "if data_select == \"THINGS\":\n",
    "    axes = visualization.show_sim_mat(\n",
    "        align_representation,\n",
    "        sim_mat_format=\"sorted\", \n",
    "        fig_dir=None,\n",
    "        ticks=\"category\",\n",
    "        \n",
    "        # keyword arguments\n",
    "        show_figure = True,\n",
    "        fig_ext=\"svg\", # you can also use \"png\" or \"pdf\", and so on. Default is \"png\".\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        cmap = 'rocket_r',\n",
    "        cbar_ticks_size=20,\n",
    "        ot_object_tick=False,\n",
    "        ot_category_tick=False,\n",
    "        xticks_size=10,\n",
    "        yticks_size=10,\n",
    "        # Note that please set ot_category_tick = True when drawing the category line.\n",
    "        draw_category_line=False,\n",
    "        category_line_color='black',\n",
    "        category_line_alpha=0.5,\n",
    "        category_line_style='dashed',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset without category information\n",
    "if data_select == \"color\":\n",
    "    axes = visualization.show_distribution(\n",
    "        align_representation, \n",
    "        fig_dir=None,\n",
    "        \n",
    "        # keyword arguments\n",
    "        show_figure = True,\n",
    "        fig_ext=\"svg\", # you can also use \"png\" or \"pdf\", and so on. Default is \"png\".\n",
    "        figsize=(6, 5), \n",
    "        title_size = 15, \n",
    "        color = 'C0',\n",
    "        bins=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset with category information\n",
    "if data_select == \"THINGS\":\n",
    "    axes = visualization.show_distribution(\n",
    "        align_representation, \n",
    "        fig_dir=None,\n",
    "        \n",
    "        # keyword arguments\n",
    "        show_figure = True,\n",
    "        fig_ext=\"svg\", # you can also use \"png\" or \"pdf\", and so on. Default is \"png\".\n",
    "        figsize=(6, 5), \n",
    "        color = 'C0',\n",
    "        bins=50\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reperesentation Similarity Aanalysis (RSA)\n",
    "This performs a conventional representation similarity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for computing RSA\n",
    "# metric = \"pearson\" or \"spearman\" by scipy.stats\n",
    "# method = \"normal\" or \"all\"\n",
    "#     \"normal\" : perform RSA with the upper-triangle matrix of sim_mat\n",
    "#     \"all\" : perform RSA with the full matrix of sim_mat\n",
    "# The result of RSA for each pair will be stored in align_representation.RSA_corr\n",
    "align_representation.calc_RSA_corr(metric = \"pearson\")\n",
    "\n",
    "# print(align_representation.RSA_corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GWOT\n",
    "The optimization results are saved in the folder named \"align_representation.data_name\" + \"representations.name\" vs \"representation.name\".  \n",
    "If you want to change the name of the saved folder, please change \"align_representation.data_name\" and \"representations.name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the computation has been completed and there is no need to recompute, set \"compute_OT\" to False. In this case, the previously calculated OT plans will be loaded.\n",
    "compute_OT = False\n",
    "\n",
    "### If the previous optimization data exists, you can delete it.\n",
    "# Setting delete_results=True will delete both the database and the directory where the results of the previous optimization are stored.\n",
    "# You can control the behavior with the following variables only when delete_results is set to True:\n",
    "# delete_database : If True, the entire database will be deleted. If False, only the studies within the database will be deleted.\n",
    "# delete_directory : If True, all directories below `data_name+pair_name` will be deleted. If False, all files under `data_name+pair_name` will be deleted, but the directories will not be deleted.\n",
    "# It is strongly recommended to set `delete_database` to False if you are managing multiple studies in the same storage (especially in the case of MySQL).\n",
    "# The code will prompt for confirmation before deleting all the results.\n",
    "delete_results = False\n",
    "delete_database = False\n",
    "delete_directory = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GWOT is performed by appling the method `gw_alignment` to the instance of `AlignRepresentations` class.   \n",
    "We show all the parameters to run GWOT computation as an example with `THINGS` dataset because this has category information label.   \n",
    "For the `color` dataset, we omit some parameters to specify (which are set to default values).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\": \n",
    "    sim_mat_format = \"sorted\" # \"sorted\" : the rows and columns of the OT plans are sorted by the coarce categories. If there is no need for sorting, set it to \"default\".\n",
    "    \n",
    "    align_representation.gw_alignment(\n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        delete_database = delete_database,\n",
    "        delete_directory = delete_directory,\n",
    "        \n",
    "        ## return_data : If True, the \"OT_format\" data will be returned in `ot_list`.\n",
    "        return_data = False,\n",
    "        \n",
    "        OT_format = sim_mat_format,\n",
    "        \n",
    "        ## save_dataframe : if True, you can save all the computed data stored in SQlite or PyMySQL in csv format (pandas.DataFrame) in the result folder.\n",
    "        save_dataframe=False,\n",
    "        \n",
    "        ## change_sampler_seed : If True, the random seed will be changed for each pair, else, the same seed defined in the next parameter will be used.  Default is False.\n",
    "        change_sampler_seed=True, \n",
    "        \n",
    "        ## fix_sampler_seed : this seed is used mainly for random sampler and TPE samapler. you can set any int (>= 0) value for sampler's seed. Default is 42.\n",
    "        fix_sampler_seed = 42, \n",
    "        \n",
    "        ## parallel_method : user can change the way of parallel computation, \"multiprocess\" or \"multithread\".\n",
    "        # \"multithread\" may be effective for most case, please choose the best one for user's environment.\n",
    "        parallel_method=\"multithread\",\n",
    "    )\n",
    "    \n",
    "    axes = visualization.show_OT(\n",
    "        align_representation,\n",
    "        OT_format=sim_mat_format,\n",
    "        \n",
    "        # user can re-define the parameter if necessary.\n",
    "        figsize=(6, 5), \n",
    "        title_size=15, \n",
    "        xlabel_size=15,\n",
    "        ylabel_size=15,\n",
    "        xticks_rotation=0,\n",
    "        cbar_ticks_size=15,\n",
    "        xticks_size=20,\n",
    "        yticks_size=20,\n",
    "        cbar_format = \"%.1e\",\n",
    "        cbar_label_size=15,\n",
    "        cmap = 'rocket_r',\n",
    "        fig_ext=\"svg\", # you can also use \"png\" or \"pdf\", and so on. Default is \"png\".\n",
    "        show_figure = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"color\":\n",
    "    sim_mat_format = \"default\"\n",
    "\n",
    "    align_representation.gw_alignment(\n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        delete_database = delete_database,\n",
    "        delete_directory = delete_directory,\n",
    "        return_data = False,\n",
    "        OT_format = sim_mat_format,\n",
    "    )\n",
    "    \n",
    "    axes = visualization.show_OT(\n",
    "        align_representation,\n",
    "        OT_format=sim_mat_format,\n",
    "        \n",
    "        # user can re-define the parameter if necessary.\n",
    "        figsize=(6, 5), \n",
    "        title_size = 15, \n",
    "        xlabel_size=15,\n",
    "        ylabel_size=15,\n",
    "        xticks_rotation=0,\n",
    "        cbar_ticks_size=15,\n",
    "        xticks_size=20,\n",
    "        yticks_size=20,\n",
    "        cbar_format = \"%.1e\",\n",
    "        cbar_label_size=15,\n",
    "        cmap = 'rocket_r',\n",
    "        fig_ext=\"svg\", # you can also use \"png\" or \"pdf\", and so on. Default is \"png\".\n",
    "        show_figure = True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluation and Visualization\n",
    "Finally, you can evaluate and visualize the unsupervise alignment of GWOT.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show how the GWD was optimized\n",
    "`show_optimization_log` will make two figures to show both the relationships between epsilons (x-axis) and GWD (y-axis), and between accuracy (x-axis) and GWD (y-axis).   \n",
    "You can re-define the parameters used for the figures after the GWOT optimization is done.  \n",
    "We show how to use the parameter setter `visualize_config.set_params` by using the `THINGS` dataset as an example.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show how the GWD was optimized (evaluation figure)\n",
    "# show both the relationships between epsilons and GWD, and between accuracy and GWD\n",
    "axes_list = visualization.show_optimization_log(\n",
    "    align_representation,\n",
    "    fig_dir=None,\n",
    "    \n",
    "    # keyword arguments\n",
    "    show_figure = False,\n",
    "    fig_ext=\"svg\", # you can also use \"png\" or \"pdf\", and so on. Default is \"png\".\n",
    "    figsize=(6, 5), \n",
    "    title_size=15, \n",
    "    cmap='rocket_r',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the accuracy of the unsupervised alignment\n",
    "There are two ways to evaluate the accuracy.  \n",
    "1. Calculate the accuracy based on the OT plan.  \n",
    "For using this method, please set the parameter `eval_type = \"ot_plan\"` in \"calc_accuracy()\".   \n",
    "  \n",
    "2. Calculate the matching rate based on the k-nearest neighbors of the embeddings.   \n",
    "For using this method, please set the parameter `eval_type = \"k_nearest\"` in \"calc_accuracy()\".   \n",
    "\n",
    "For both cases, the accuracy evaluation criterion can be adjusted by setting `top_k_list`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the accuracy based on the OT plan. \n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"ot_plan\")\n",
    "\n",
    "ax = visualization.plot_accuracy(\n",
    "    align_representation,\n",
    "    eval_type = \"ot_plan\",\n",
    "    scatter = True,\n",
    "    show_figure=True,\n",
    ")\n",
    "\n",
    "top_k_accuracy = align_representation.top_k_accuracy # you can get the dataframe directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the matching rate based on the k-nearest neighbors of the embeddings.\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"k_nearest\", return_dataframe=False)\n",
    "\n",
    "ax = visualization.plot_accuracy(\n",
    "    align_representation,\n",
    "    eval_type = \"k_nearest\",\n",
    "    scatter = True,\n",
    "    show_figure=True,\n",
    ")\n",
    "\n",
    "k_nearest_matching_rate = align_representation.k_nearest_matching_rate # you can get the dataframe directly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calclate the category level accuracy\n",
    "When there are category labels, you can also compute the acccuracy at the category level.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the data has the coarse category labels, you can observe the category level accuracy.\n",
    "# This accuracy is calculated based on the OT plan.\n",
    "if data_select == \"THINGS\":\n",
    "    align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"category\", category_mat=category_mat)\n",
    "    ax = visualization.plot_accuracy(\n",
    "        align_representation,\n",
    "        eval_type = \"category\",\n",
    "        scatter = True,\n",
    "        show_figure=True,\n",
    "    )\n",
    "\n",
    "    category_level_accuracy = align_representation.category_level_accuracy # you can get the dataframe directly "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the aligned embeddings\n",
    "Using the optimized transportation plans, you can align the embeddings of each representation in a common space in an unsupervised manner.  \n",
    "The `\"pivot\"` refers to the target embeddings space to which the other embeddings will be aligned.   \n",
    "You have the option to set the `\"pivot\"` as one of the representations or the barycenter.  \n",
    "Please ensure that 'pair_number_list' includes all pairs between the pivot and the other Representations.  \n",
    "\n",
    "If you wish to utilize the barycenter, please make use of the method `AlignRepresentation.barycenter_alignment()`.  \n",
    "You can use it in the same manner as you did with `AlignRepresentation.gw_alignment()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"color\":\n",
    "    low_emb_list = align_representation.calc_embedding(\n",
    "        dim=3,\n",
    "        pivot=0,\n",
    "        emb_name=\"TSNE\",\n",
    "        return_data=True,\n",
    "    )\n",
    "\n",
    "    file_path = \"../data/color/color_dict.csv\"\n",
    "    data_color = pd.read_csv(file_path)\n",
    "    color_labels = data_color.columns.values\n",
    "\n",
    "    ax = visualization.plot_embedding(\n",
    "        align_representation,\n",
    "        dim=3,\n",
    "        \n",
    "        # keyword arguments\n",
    "        fig_ext=\"svg\",\n",
    "        color_labels=color_labels,\n",
    "        cmap=None, # If \"color_labels=None\", you have the option to choose the color map (e.g. \"cool\").\n",
    "        alpha=1.,\n",
    "        figsize=(10, 10), \n",
    "        xlabel=\"PC1\", \n",
    "        ylabel=\"PC2\",\n",
    "        zlabel=\"PC3\", \n",
    "        legend_size=10,\n",
    "        font=\"DejaVu Serif\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color labels and coarse category labels if exist.\n",
    "# If there are a large number of objects within each group, such as in the case of THINGS data, visualizing all the points may not be meaningful. \n",
    "# In such cases, it is necessary to specify specific coarse category labels that you would like to visualize.\n",
    "if data_select == \"THINGS\":\n",
    "    category_name_list = [\"bird\", \"insect\", \"plant\", \"clothing\",  \"furniture\", \"fruit\", \"drink\", \"vehicle\"] # please specify the categories that you would like to visualize.\n",
    "    category_mat = pd.read_csv(\"../data/THINGS/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)   \n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat, category_name_list, show_numbers = True)  \n",
    "    \n",
    "    # The figures made from the following code will be saved in the directory \"/main_results_dir/data_name/visualize_embedding\".\n",
    "    low_emb_list = align_representation.calc_embedding(\n",
    "        dim=3,\n",
    "        pivot=0,\n",
    "        emb_name=\"PCA\",\n",
    "        category_idx_list=category_idx_list,\n",
    "        return_data=True,\n",
    "    )\n",
    "    \n",
    "    ax = visualization.plot_embedding(\n",
    "        align_representation,\n",
    "        dim=3,\n",
    "        category_name_list=category_name_list,\n",
    "        num_category_list=num_category_list,\n",
    "        \n",
    "        # keyword arguments\n",
    "        fig_ext=\"svg\",\n",
    "        cmap=None, # If \"color_labels=None\", you have the option to choose the color hue as either \"cool\", \"warm\", or \"None\".\n",
    "        figsize=(11, 11), \n",
    "        xlabel=\"PC1\", \n",
    "        ylabel=\"PC2\",\n",
    "        zlabel=\"PC3\", \n",
    "        marker_size=6,\n",
    "        legend_size=10,\n",
    "        font=\"DejaVu Serif\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Delete Results\n",
    "\n",
    "If you want to delete the directory, the figures and the database  where all the computation results are saved, you can use `align_representation.drop_gw_alignment_files`.  \n",
    "Please be very careful because this operation is irreversible.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align_representation.drop_gw_alignment_files(\n",
    "#     drop_all=True,\n",
    "#     delete_database=True,\n",
    "#     delete_directory=True,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
