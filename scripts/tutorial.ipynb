{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tutorial for Gromov-Wassserstein unsupervised alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from src.align_representations import Representation, AlignRepresentations, OptimizationConfig, VisualizationConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Prepare dis-similarity matrices\n",
    "First, you need to prepare dis-similarity (distance) matrices from your data.  \n",
    "Then, you need to input the similarity matrices into the list \"representations\" as follows.  \n",
    "This list constains instances \"Representation\" where \"name\" means the names of similarity matrices, which are used for the filename.\n",
    "\n",
    "## Load data\n",
    "you can choose the following data\n",
    "1. 'color': human similarity judgements of 93 colors for 5 paricipants groups\n",
    "1. 'THINGS' : human similarity judgements of 1854 objects for 4 paricipants groups\n",
    "\n",
    "\"data_select\" in next code block can define which dataset are going to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of representations where similarity matrices are included\n",
    "representations = list()\n",
    "\n",
    "# select data\n",
    "data_select = \"THINGS\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No1. `color`\n",
    "For this data, we directly input similarity matrices of 93 colors into \"representations\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create \"Representation\" instance\n",
    "if data_select == 'color':\n",
    "    n_representations = 5 # Set the number of representations. This number must be equal to or less than the number of groups.\n",
    "    metric = \"euclidean\" # Please set metric that can be used in \"scipy.distance.cdist()\"\n",
    "    \n",
    "    data_path = '../data/num_groups_5_seed_0_fill_val_3.5.pickle'\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    sim_mat_list = data[\"group_ave_mat\"]\n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\" # \"name\" will be used as a filename for saving the results\n",
    "        sim_mat = sim_mat_list[i] # similarity matrix of group i\n",
    "        # make an instance \"Representation\" with settings \n",
    "        representation = Representation(\n",
    "            name = name, \n",
    "            metric = metric,\n",
    "            sim_mat = sim_mat,  #: np.ndarray\n",
    "            embedding = None,   #: np.ndarray \n",
    "            get_embedding = False, # Default is False.\n",
    "            MDS_dim = 3, # used for visualization\n",
    "            object_labels = None,\n",
    "            category_name_list = None,\n",
    "            num_category_list = None,\n",
    "            category_idx_list = None,\n",
    "            func_for_sort_sim_mat = None,\n",
    "       ) \n",
    "        representations.append(representation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No.2 `THINGS`\n",
    "For this data, we input embeddings of each object into representations and then, compute similarity matrices from the embeddings.  \n",
    "This dataset has information of category labels. We demonstrate how to define it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    # define the label information of the dataset\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)\n",
    "    \n",
    "    # define the parameters for category (or label) info. \n",
    "    # Users can define these by themselves if they use a different dataset and the format of parameters are the same.\n",
    "    # get_category_data and sort_matrix_with_categories are functions specialied for this dataset\n",
    "    from src.utils.utils_functions import get_category_data, sort_matrix_with_categories\n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat)\n",
    "    \n",
    "    n_representations = 4 # Set the number of representations. This number must be equal to or less than the number of groups.\n",
    "    metric = \"euclidean\" # Please set metric that can be used in \"scipy.distance.cdist()\"\n",
    "    \n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\"\n",
    "        embedding = np.load(f\"../data/THINGS_embedding_Group{i+1}.npy\")[0]\n",
    "        \n",
    "        representation = Representation(\n",
    "            name = name, \n",
    "            embedding = embedding, # the similarity matrix will be calculated by this embedding.\n",
    "            metric = metric,\n",
    "            get_embedding = True, # Default is False. If True, the similarity matrix will be calculated by the embedding.\n",
    "            object_labels = object_labels,\n",
    "            category_name_list = category_name_list,\n",
    "            category_idx_list = category_idx_list,\n",
    "            num_category_list = num_category_list,\n",
    "            func_for_sort_sim_mat = sort_matrix_with_categories\n",
    "        )\n",
    "        \n",
    "        representations.append(representation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Set the parameters for the optimazation of GWOT\n",
    "\n",
    "## Optimization Config  \n",
    "\n",
    "#### Most important options to check for your application:\n",
    "`eps_list, num_trial` are essential for computing the GW alignment.  \n",
    "You can first use default values for the other options.  \n",
    "\n",
    "You need to choose appropriate ranges of epsilon, \"eps_list\".  \n",
    "If epsilon is not in appropriate ranges, the optimization may not work properly.  \n",
    "Also, epsilon range is critical for finding good local optimum.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OptimizationConfig(\n",
    "    ### Set the range of epsilon\n",
    "    # set only the minimum value and maximum value for 'tpe' sampler\n",
    "    # for 'grid' or 'random' sampler, you can also set the step size\n",
    "    eps_list = [1, 10], # [1, 10] for THINGS data, [0.02, 0.2] for colors data\n",
    "    eps_log = True, # whether epsilon is sampled at log scale or not\n",
    "    num_trial = 4, # set the number of trials, i.e., the number of epsilon values evaluated in optimization. default : 20\n",
    "    sinkhorn_method='sinkhorn', # please choose the method of sinkhorn implemented by POT (URL : https://pythonot.github.io/gen_modules/ot.bregman.html#id87)\n",
    "    \n",
    "    ### Set the device ('cuda' or 'cpu') and variable type ('torch' or 'numpy')\n",
    "    to_types = 'torch', # user can choose \"numpy\" or \"torch\". please set \"torch\" if one wants to use GPU.\n",
    "    device = 'cuda', # \"cuda\" or \"cpu\"; for numpy, only \"cpu\" can be used. \n",
    "    \n",
    "    ### Parallel Computation (requires n_jobs > 1, available both for numpy and torch)\n",
    "    n_jobs = 4, # n_jobs : the number of worker to compute. if n_jobs = 1, normal computation will start. \n",
    "    parallel_method = \"multithread\", # \"multiprocess\" or \"multithread\". Default is \"multithread\".\n",
    "    multi_gpu = [1,2], # This parameter is only for \"torch\". # \"True\" : all the GPU installed in your environment, \"list (e.g.[0,2,3])\"\" : cuda:0,2,3, and \"False\" : single gpu (or cpu for numpy) will use.\n",
    "    \n",
    "    ### Set the database URL to store the optimization results (either PyMySQL or SQLite. For using PyMySQL, some additional setting beforehand will be needed).  \n",
    "    # To use remote databases, you need to start the database server beforehand. For detailed instruction, please refer to the Optuna official tutorial:  \n",
    "    # https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html  \n",
    "    \n",
    "    storage = None, # When using SQLite, the database file is automatically created, so you only need to set None.\n",
    "    # storage = 'mysql+pymysql://root@localhost/oizumi',\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # 1. initialization of transportation plan\n",
    "    # 2. 'uniform': uniform matrix, 'diag': diagonal matrix\n",
    "    # 3. 'random': random matrix, 'permutation': permutation matrix\n",
    "    # you can select multiple options (e.g. init_plans_list = ['uniform', 'random'])\n",
    "    init_plans_list = ['random'],\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # n_iter : the number of random initial matrices for 'random' or 'permutation' options：default: 100\n",
    "    # max_iter : the maximum number of iteration for GW optimization: default: 1000\n",
    "    n_iter = 1,\n",
    "    max_iter = 200,\n",
    "    \n",
    "    ### folder or file name when saving the result\n",
    "    # Optimization results are saved in the folder by \"config.data_name\" + \"representations.name\" vs \"representation.name\".\n",
    "    # If you want to change the name of the saved folder, please change \"config.data_name\" and \"representations.name\".\n",
    "    data_name = data_select, # Please rewrite this name if users want to use their own data.\n",
    "    \n",
    "    ### user can delete the result data if existed and they want.  \n",
    "    # Delete previous optimization results or not  \n",
    "    # If the same filename has different search space, optuna may not work well.\n",
    "    delete_study = False, \n",
    "    \n",
    "    ### choose sampler implemented by Optuna\n",
    "    # 1. 'random': randomly select epsilon between the range of epsilon\n",
    "    # 2. 'grid': grid search between the range of epsilon\n",
    "    # 3. 'tpe': Bayesian sampling\n",
    "    sampler_name = 'tpe',\n",
    "    \n",
    "    ### choose pruner\n",
    "    # 1. 'median': Pruning if the score is below the past median at a certain point in time  \n",
    "    #     n_startup_trials: Do not activate the pruner until this number of trials has finished  \n",
    "    #     n_warmup_steps: Do not activate the pruner for each trial below this step  \n",
    "        \n",
    "    # 2. 'hyperband': Use multiple SuccessiveHalvingPrunerd that gradually longer pruning decision periods and that gradually stricter criteria  \n",
    "    #     min_resource: Do not activate the pruner for each trial below this step  \n",
    "    #     reduction_factor: How often to check for pruning. Smaller values result in more frequent pruning checks. Between 2 to 6.  \n",
    "        \n",
    "    # 3. 'nop': no pruning\n",
    "    pruner_name = 'hyperband',\n",
    "    pruner_params = {'n_startup_trials': 1, \n",
    "                     'n_warmup_steps': 2, \n",
    "                     'min_resource': 2, \n",
    "                     'reduction_factor' : 3\n",
    "                    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisualizationConfig\n",
    "VisualizationConfig will help user to make the figure to visualize the results of GW alignment. \n",
    "\n",
    "For here, we just want to introduce all the parameters will be used for this instance, and we will change some of them later for each dataset.\n",
    "\n",
    "Please keep in mind that user can get the raw results data if they want to make the figures by themselves.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_matrix = VisualizationConfig(\n",
    "    ### Please set the parameters below that can be used in \"mttplotlib.pyplot\"\n",
    "    figsize=(8, 6), \n",
    "    title_size = 15, \n",
    "    cmap = 'cividis',\n",
    "    cbar_ticks_size=20,\n",
    "    ticks_size=5,\n",
    "    xticks_rotation=90,\n",
    "    yticks_rotation=0,\n",
    "    legend_size=5,\n",
    "    xlabel=None,\n",
    "    xlabel_size=15,\n",
    "    ylabel=None,\n",
    "    ylabel_size=15,\n",
    "    zlabel=None,\n",
    "    zlabel_size=15,\n",
    "    color_labels=None,\n",
    "    color_hue=None,\n",
    "    markers_list=None,\n",
    "    marker_size=30,\n",
    "    \n",
    "    ### Set the parameters for showing the boundary of category or label info if the dataset have. If not, please draw_category_line = False.\n",
    "    draw_category_line=True,\n",
    "    category_line_color='C2',\n",
    "    category_line_alpha=0.2,\n",
    "    category_line_style='dashed',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Unsupervised alignment between Representations\n",
    "For GW aligment, we create an instance \"AlignRepresentations\" where we put the list of instance \"representations\".  \n",
    "The instance \"AlignRepresentations\" has methods for Representation Similarity Analysis (RSA), Gromov-Wasserstein (GW) alignment, the evaluation of the GW alignment.  \n",
    "\n",
    "This instance will compute all the pairs based on `representations_list` we defined at the beggining of this notebook.   \n",
    "If you want to limit the pairs that are applied GW alignment, please set “AlignRepresentations.pair_number_list”. (e.g. pair_number_list = [[0, 1], [0, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an \"AlignRepresentations\" instance\n",
    "align_representation = AlignRepresentations(\n",
    "    representations_list=representations,\n",
    "    pair_number_list='all', #If you want to limit the pairs that are applied GW alignment, please set “AlignRepresentations.pair_number_list”. (e.g. pair_number_list = [[0, 1], [0, 2]])\n",
    "    histogram_matching=False,\n",
    "    config=config,\n",
    "    metric=\"cosine\", # 武田さんにコメントを書いてもらう。\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset No.1 : color \n",
    "if data_select == \"color\":\n",
    "    sim_mat_format = \"default\"\n",
    "    visualize_matrix = VisualizationConfig(figsize=(8, 6), title_size = 15)\n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format = sim_mat_format, \n",
    "        visualization_config = visualize_matrix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset No.2 : THINGS\n",
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "    visualize_matrix = VisualizationConfig(\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        cmap = 'Blues',\n",
    "        cbar_ticks_size=20,\n",
    "        \n",
    "        draw_category_line=True,\n",
    "        category_line_color='C4',\n",
    "        category_line_alpha=0.5,\n",
    "        category_line_style='dashed',\n",
    "       \n",
    "        )\n",
    "    \n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format=sim_mat_format, \n",
    "        visualization_config=visualize_matrix,\n",
    "        fig_dir=None,\n",
    "        show_distribution=False,\n",
    "        ticks='category'\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reperesentation Similarity Aanalysis (RSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### arguments for computing RSA\n",
    "# metric = \"pearson\" or \"spearman\" by scipy.stats\n",
    "# method = \"normal\" or \"all\"\n",
    "#     \"normal\" : the data to take the RSA is the upper-triangle of sim_mat (numpy.triu_indices(sim_mat.shpe[0], k=1)).\n",
    "#     \"all\" : the data to take the RSA is all the values of dis-similarity matrix (sim_mat.flatten()).\n",
    "align_representation.RSA_get_corr(metric = \"pearson\", method = 'all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing GW Alignment.\n",
    "Optimization results are saved in the folder by \"config.data_name\" + \"representations.name\" vs \"representation.name\".  \n",
    "If you want to change the name of the saved folder, please change \"config.data_name\" and \"representations.name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_OT = False # If the computation was done and no need for, turn \"compute_OT\" False, then OT plans calculated before is loaded.\n",
    "\n",
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "    visualize_matrix = VisualizationConfig(figsize=(8, 6), title_size = 15, category_line_color = 'C1')\n",
    "\n",
    "    ot_list = align_representation.gw_alignment(\n",
    "        results_dir = \"../results\",\n",
    "        compute_OT = compute_OT,  \n",
    "        return_data = False, # If True, the data will be stored in `ot_list`.\n",
    "        return_figure = True,\n",
    "        OT_format = sim_mat_format, # \"default\", \"sorted\" or \"both\" (= \"default\" and \"sorted\").\n",
    "        visualization_config = visualize_matrix,\n",
    "        show_log=False, # if True, this will show the figures how the GWD was optimized.\n",
    "        fig_dir=None, # you can define the path to save the figures (.png). If None, the figures will be saved in the same subfolder in \"results_dir\"\n",
    "        ticks = 'category', # you can use \"objects\" or \"category\" or \"None\"\n",
    "    )\n",
    "\n",
    "if data_select == \"color\":\n",
    "    visualize_matrix = VisualizationConfig(figsize=(10, 10), title_size = 15)\n",
    "\n",
    "    align_representation.gw_alignment(\n",
    "        results_dir = \"../results\",\n",
    "        compute_OT = compute_OT,\n",
    "        return_data = False,\n",
    "        return_figure = True,\n",
    "        OT_format = sim_mat_format, # \"default\"\n",
    "        visualization_config = visualize_matrix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show how the GWD was optimized\n",
    "align_representation.show_optimization_log(results_dir=\"../results\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluating the unsupervised alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the accuracy of the optimized OT matrix\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"ot_plan\")\n",
    "align_representation.plot_accuracy(eval_type = \"ot_plan\", scatter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the matching rate of k-nearest neighbors of embeddings\n",
    "## Matching rate of k-nearest neighbors \n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"k_nearest\")\n",
    "align_representation.plot_accuracy(eval_type = \"k_nearest\", scatter = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the aligned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color labels and category data if exist.\n",
    "if data_select == \"THINGS\":\n",
    "    category_name_list = [\"bird\", \"insect\", \"plant\", \"clothing\",  \"furniture\", \"fruit\", \"drink\", \"vehicle\"]\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)   \n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat, category_name_list, show_numbers = True)  \n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        figsize=(15, 15), \n",
    "        xlabel=\"PC1\",\n",
    "        ylabel=\"PC2\", \n",
    "        zlabel=\"PC3\", \n",
    "        marker_size=20,\n",
    "        legend_size=10\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3,  \n",
    "        visualization_config=visualization_embedding,\n",
    "        category_name_list=category_name_list, \n",
    "        category_idx_list=category_idx_list, \n",
    "        num_category_list=num_category_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == 'color':\n",
    "    file_path = \"../data/color_dict.csv\"\n",
    "    data_color = pd.read_csv(file_path)\n",
    "    color_labels = data_color.columns.values\n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        color_labels=color_labels, \n",
    "        figsize=(15, 15), \n",
    "        xlabel=\"PC1\", \n",
    "        ylabel=\"PC2\",\n",
    "        zlabel=\"PC3\", \n",
    "        legend_size=10\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3, \n",
    "        visualization_config=visualization_embedding\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## category level analysis\n",
    "User can use this analysis if the dataset has category info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calclate the category level accuracy\n",
    "if data_select == \"THINGS\":\n",
    "    align_representation.calc_category_level_accuracy(category_mat=category_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
