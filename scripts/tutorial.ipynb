{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tutorial for Gromov-Wassserstein unsupervised alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import torch\n",
    "\n",
    "from src.align_representations import Representation, AlignRepresentations, OptimizationConfig, VisualizationConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Prepare dissimilarity matrices or embeddings from the data\n",
    "First, you need to prepare dissimilarity matrices or embeddings from your data.  \n",
    "To store dissimilarity matrices or embeddings, an instance of the class `Representation` is used.   \n",
    "Please put your dissimilarity matrices or embeddings into the variables `sim_mat` or `embedding` in this instance.   \n",
    "\n",
    "## Load data\n",
    "You can select the data from the following options:   \n",
    "1. `simulation`: Synthetic data illustrating difference between supervised an unsupervised alignment    \n",
    "2. `AllenBrain`: Neuropixel data recorded in the visual area of mice from the Allen Brain Observatory   \n",
    "3. `THINGS` : Human similarity judgments of 1854 objects for 4 groups of participants from the THINGS data    \n",
    "4. `DNN`: Latent variables from vision DNNs (AlexNet and VGG19) for a subset of ImageNet   \n",
    "5. `color`: Human similarity judgements of 93 colors for 5 groups of participants from the data used in Kawakita et al., 2023, PsyArxiv   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of representations where the instances of \"Representation\" class are included\n",
    "representations = list()\n",
    "\n",
    "# select data : \"simulation\", \"AllenBrain\", \"THINGS\", \"DNN\", \"color\"\n",
    "data_select = \"DNN\"\n",
    "# data_select = \"THINGS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No.3 `THINGS`\n",
    "In this case, we assign the embeddings of 1854 natural objects to the instance `Representation`.   \n",
    "This instance compute the dissimilarity matrices from the embeddings based on `metric`.  \n",
    "\n",
    "In addition to the object labels, this dataset includes coarse category labels for each object.   \n",
    "These coarse category labels are used for the evaluation and visualization of alignment.  \n",
    "The category information is stored in the variables `category_idx_list` and `category_name_list`.  \n",
    "For your application, please put category information in these variables.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    # define the coarce category labels\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)\n",
    "    \n",
    "    # calculate the parameters for the coarce category labels\n",
    "    # Please prepare equivalent parameters when using other datasets.\n",
    "    from src.utils.utils_functions import get_category_data, sort_matrix_with_categories # get_category_data and sort_matrix_with_categories are functions specialied for this dataset\n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat)\n",
    "    \n",
    "    n_representations = 3 # Set the number of the instanses of \"Representation\". This number must be equal to or less than the number of the groups. 4 is the maximum for this data.\n",
    "    metric = \"euclidean\" # Please set the metric that can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    \n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\" # the name of the representation\n",
    "        embedding = np.load(f\"../data/THINGS_embedding_Group{i+1}.npy\")[0] # the dissimilarity matrix will be computed with this embedding based on the metric\n",
    "        \n",
    "        representation = Representation(\n",
    "            name=name,\n",
    "            embedding=embedding,\n",
    "            metric=metric,\n",
    "            get_embedding=False, # If there is the embeddings, plese set this variable \"False\".\n",
    "            object_labels=object_labels, # the labels of the objects\n",
    "            category_name_list=category_name_list, # the names of the categories\n",
    "            category_idx_list=category_idx_list, # the indexes of the categories. This is used for the evaluation and the visualization of the unsuperivsed alignment.\n",
    "            num_category_list=num_category_list, \n",
    "            func_for_sort_sim_mat=sort_matrix_with_categories,\n",
    "        )\n",
    "        \n",
    "        representations.append(representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No4. `DNN`\n",
    "The latent features of two vision DNNs(Deep Neural Network), AlexNet and VGG19, are extracted.   \n",
    "The number of image used for this is 1000 (= 20 class * 50 images), subsampled from the validation set of ImageNet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if data_select == 'DNN':\n",
    "    \n",
    "    ### define the category info from label data in the validation dataset.\n",
    "    lab_path = '../data/DNN/label.pt'\n",
    "    lab = torch.load(lab_path).to('cpu').numpy()\n",
    "    \n",
    "    ### category_mat needs to be an one-hot encoding. \n",
    "    category_mat = pd.get_dummies(lab)\n",
    "    \n",
    "    category_mat.columns = np.load('../data/DNN/label_name.npy')\n",
    "    \n",
    "    from src.utils.utils_functions import get_category_data, sort_matrix_with_categories \n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat = category_mat)\n",
    "    \n",
    "    model_name_list = ['ResNet50', 'VGG19']\n",
    "    \n",
    "    for model_name in model_name_list:\n",
    "        \n",
    "        emb_path = f'../data/DNN/{model_name}_emb.pt'\n",
    "        cos_path = f'../data/DNN/{model_name}_cosine.pt'\n",
    "        \n",
    "        emb = torch.load(emb_path).to('cpu').numpy()\n",
    "        sim_mat = torch.load(cos_path).to('cpu').numpy()\n",
    "    \n",
    "        model_rep = Representation(\n",
    "            name=model_name, \n",
    "            sim_mat=sim_mat, \n",
    "            embedding=emb, \n",
    "            get_embedding=False,\n",
    "            object_labels=object_labels,\n",
    "            category_name_list=category_name_list,\n",
    "            category_idx_list=category_idx_list,\n",
    "            num_category_list=num_category_list, \n",
    "            func_for_sort_sim_mat=sort_matrix_with_categories,\n",
    "        )\n",
    "  \n",
    "        representations.append(model_rep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No5. `color`\n",
    "In this case, we directly assign the dissimilarity matrices of 93 colors to \"Representation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create \"Representation\" instance\n",
    "if data_select == 'color':\n",
    "    n_representations = 4 # Set the number of the instanses of \"Representation\". This number must be equal to or less than the number of the groups. 5 is the maximum for this data.\n",
    "    metric = \"euclidean\" # Please set the metric that can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    \n",
    "    data_path = '../data/num_groups_5_seed_0_fill_val_3.5.pickle'\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    sim_mat_list = data[\"group_ave_mat\"]\n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\" # \"name\" will be used as a filename for saving the results\n",
    "        sim_mat = sim_mat_list[i] # the dissimilarity matrix of the i-th group\n",
    "        # make an instance \"Representation\" with settings \n",
    "        representation = Representation(\n",
    "            name=name, \n",
    "            metric=metric,\n",
    "            sim_mat=sim_mat,  #: np.ndarray\n",
    "            embedding=None,   #: np.ndarray \n",
    "            get_embedding=True, # If true, the embeddings are computed from the dissimilarity matrix automatically using the MDS function. Default is False. \n",
    "            MDS_dim=3, # If \"get embedding\" is True, please set the dimensions of the embeddings.\n",
    "            object_labels=None,\n",
    "            category_name_list=None,\n",
    "            num_category_list=None,\n",
    "            category_idx_list=None,\n",
    "            func_for_sort_sim_mat=None,\n",
    "       ) \n",
    "        representations.append(representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Set the parameters for the optimazation of GWOT\n",
    "Second, you need to set the parameters for the optimization of GWOT.    \n",
    "For most of the parameters, you can start with the default values.   \n",
    "However, there are some essential parameters that you need to check for your original applications.  \n",
    "\n",
    "## Optimization Config  \n",
    "\n",
    "#### Most important parameters to check for your application:\n",
    "`eps_list`: The range of the values of epsilon for entropic GWOT.   \n",
    "If epsilon is not in appropriate ranges (if it is too low), the optimization may not work properly.   \n",
    "Although the algorithm will find good epsilon values after many trials, it is a good practice to narrow down the range beforehand.   \n",
    "\n",
    "`num_trial`: The number of trials to test epsilon values from the specified range.   \n",
    "This number directly determines the quality of the unsupervised alignment.   \n",
    "You should set this number high enough to find good local minima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Most important parameters\n",
    "# Set the range of the epsilon\n",
    "# set the minimum value and maximum value for 'tpe' sampler\n",
    "# for 'grid' or 'random' sampler, you can also set the step size\n",
    "if data_select == \"THINGS\":\n",
    "    eps_list_tutorial = [1, 10]\n",
    "    device = 'cpu'\n",
    "    to_types = 'numpy'\n",
    "\n",
    "if data_select == \"color\":\n",
    "    eps_list_tutorial = [0.02, 0.2]\n",
    "    device = 'cpu'\n",
    "    to_types = 'numpy'\n",
    "\n",
    "if data_select == \"DNN\":\n",
    "    eps_list_tutorial = [1e-4, 1e-2]\n",
    "    device = 'cuda'\n",
    "    to_types = 'torch'\n",
    "    \n",
    "# whether epsilon is sampled at log scale or not\n",
    "eps_log = True\n",
    "\n",
    "# set the number of trials, i.e., the number of epsilon values evaluated in optimization. default : 4\n",
    "num_trial = 4\n",
    "\n",
    "### Set the parameters for optimization\n",
    "# initialization of transportation plan\n",
    "# 'uniform': uniform matrix, 'diag': diagonal matrix', random': random matrix, 'permutation': permutation matrix\n",
    "# Select multiple options was deprecated.\n",
    "init_mat_plan = \"random\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If user wants to use some user-defined init matrices...\n",
    "For ”user_define”, it is note that all the initialization plans need to be written in Numpy even when PyTorch is used for the optimization.  \n",
    "The user can define a single or multiple plans before the optimization starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if init_mat_plan == \"user_define\":\n",
    "    import ot\n",
    "    size = representation.sim_mat.shape[0]\n",
    "    user_define_mat_random = np.random.randn(size, size)\n",
    "    user_define_mat_random = user_define_mat_random / user_define_mat_random.sum()\n",
    "    user_define_init_mat_list = [user_define_mat_random, np.outer(ot.unif(size), ot.unif(size))]\n",
    "else:\n",
    "    user_define_init_mat_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OptimizationConfig(    \n",
    "    eps_list = eps_list_tutorial, # [1, 10] for THINGS data, [0.02, 0.2] for colors data\n",
    "    eps_log = eps_log, # whether epsilon is sampled at log scale or not\n",
    "    num_trial = num_trial, # set the number of trials, i.e., the number of epsilon values evaluated in optimization. default : 4\n",
    "    sinkhorn_method='sinkhorn', # please choose the method of sinkhorn implemented by POT (URL : https://pythonot.github.io/gen_modules/ot.bregman.html#id87). For using GPU, \"sinkhorn_log\" is recommended.\n",
    "    \n",
    "    ### Set the device ('cuda' or 'cpu') and variable type ('torch' or 'numpy')\n",
    "    to_types = to_types, # user can choose \"numpy\" or \"torch\". please set \"torch\" if one wants to use GPU.\n",
    "    device = device, # \"cuda\" or \"cpu\"; for numpy, only \"cpu\" can be used. \n",
    "    data_type = \"double\", # user can define the dtypes both for numpy and torch, \"float(=float32)\" or \"double(=float64)\". For using GPU with \"sinkhorn\", double is storongly recommended.\n",
    "    \n",
    "    ### Parallel Computation (requires n_jobs > 1, available both for numpy and torch)\n",
    "    n_jobs = 3, # n_jobs : the number of worker to compute. if n_jobs = 1, normal computation will start. \"Multithread\" is used for Parallel computation.\n",
    "    multi_gpu = True, # This parameter is only for \"torch\". # \"True\" : all the GPU installed in your environment are used, \"list (e.g.[0,2,3])\"\" : cuda:0,2,3, and \"False\" : single gpu (or cpu for numpy) will use.\n",
    "    \n",
    "    ### Set the db_params to create database URL to store the optimization results (either PyMySQL or SQLite. For using PyMySQL, some additional setting beforehand will be needed).  \n",
    "    # The database URL in sqlalchemy is like \"dialect+driver://username:password@host:port/database\". See the following page for details. https://docs.sqlalchemy.org/en/20/core/engines.html\n",
    "    # If you want to use SQLite, it's enough to set \"db_params={\"drivername\": \"sqlite\"}\".\n",
    "    # This package generates 1 database per each study.\n",
    "\n",
    "    db_params={\"drivername\": \"sqlite\"},\n",
    "    # db_params={\"drivername\": \"mysql+pymysql\", \"username\": \"root\", \"password\": \"****\", \"host\": \"localhost\"},\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # 'uniform': uniform matrix, 'diag': diagonal matrix', random': random matrix\n",
    "    init_mat_plan = init_mat_plan,\n",
    "    \n",
    "    # user-defined initialization plans\n",
    "    user_define_init_mat_list = user_define_init_mat_list,\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # n_iter : the number of random initial matrices for 'random' or 'permutation' options：default: 1\n",
    "    # max_iter : the maximum number of iteration for GW optimization: default: 200\n",
    "    n_iter = 1,\n",
    "    max_iter = 1000,\n",
    "    \n",
    "    ### choose sampler implemented by Optuna\n",
    "    # 1. 'random': randomly select epsilon between the range of epsilon\n",
    "    # 2. 'grid': grid search between the range of epsilon\n",
    "    # 3. 'tpe': Bayesian sampling\n",
    "    sampler_name = 'tpe',\n",
    "    \n",
    "    ### choose pruner\n",
    "    # 1. 'median': Pruning if the score is below the past median at a certain point in time  \n",
    "    #     n_startup_trials: Do not activate the pruner until this number of trials has finished  \n",
    "    #     n_warmup_steps: Do not activate the pruner for each trial below this step  \n",
    "        \n",
    "    # 2. 'hyperband': Use multiple SuccessiveHalvingPrunerd that gradually longer pruning decision periods and that gradually stricter criteria  \n",
    "    #     min_resource: Do not activate the pruner for each trial below this step  \n",
    "    #     reduction_factor: How often to check for pruning. Smaller values result in more frequent pruning checks. Between 2 to 6.  \n",
    "        \n",
    "    # 3. 'nop': no pruning\n",
    "    pruner_name = 'hyperband',\n",
    "    pruner_params = {'n_startup_trials': 1, \n",
    "                     'n_warmup_steps': 2, \n",
    "                     'min_resource': 2, \n",
    "                     'reduction_factor' : 3\n",
    "                    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Gromov-Wasserstein Optimal Transport (GWOT) between Representations\n",
    "Third, you perform GWOT between the instanses of \"Representation\", by using the class `AlignRepresentations`.  \n",
    "This class has methods for the optimization of entropic Gromov-Wasserstein distance, and the evaluation of the GWOT (Step 4).  \n",
    "This class also has a method to perform conventional Representation Similarity Analysis (RSA).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Directory for saving the results of GWOT\n",
    "\n",
    "Here is the directory structure to save the results below.  \n",
    "\n",
    "```\n",
    "    main_results_dir /\n",
    "        ├─ data_name (e.g. `THINGS`) /\n",
    "            ├─ data_name + pair_name (e.g. `THINGS_Group1_vs_Group2`) /\n",
    "                ├─ sampler_name (e.g. `random`) /\n",
    "                    ├─ figure /\n",
    "                    │   ├─ some figures (e.g. acc_gwd_eps.png)\n",
    "                    ├─ data /\n",
    "                    │   ├─ OT.npy (numpy) or OT.pt (torch)\n",
    "                    │   \n",
    "                    ├─ database (if using sqlite; e.g. `THINGS_Group1_vs_Group2_random.db`)\n",
    "``` \n",
    "\n",
    "- This folder structure will be automatically made in the process of GWOT optimization.\n",
    "- User is assumed to provide the names of the followings: `main_result_dir`,  `data_name`, and `pair_name`(defined by the two `representations.name`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Choose pairs of representations for GWOT optimization\n",
    "By default, GWOT will be performed for all the pairs of given representations.   \n",
    "You can specify particular pairs that you want to compute as follows.   \n",
    "Also, you can change epsilon range for particular pairs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default setting (compute all the pairs if `pair_computed` is None)\n",
    "pairs_computed = None\n",
    "\n",
    "# If you wish to compute only partiuclar pairs or all the pairs which have one partiuclar representation, you can specify them as follows.\n",
    "# In this example below,  \n",
    "# \"Group1\": all the pairs with \"Group1\"  \n",
    "# \"Group2_vs_Group4\": only the pair named \"Group2_vs_Group4\"\n",
    "# Please use \"_vs_\" between the representations' names for a single pair. \n",
    "# And please also keep in mind that the name of each pair will be made by the order of `representations_list`, which means \"Group4_vs_Group2\" can't be accepted.\n",
    "\n",
    "# pairs_computed = [\"Group1\", \"Group2_vs_Group4\"]\n",
    "\n",
    "# Default setting (use the same epsilon range for all the pairs)\n",
    "specific_eps_list = None\n",
    "\n",
    "# If you wish to change the epsilon range for particular pairs, you can specify them as follows.\n",
    "# specific_eps_list = {'Group1': [0.02, 0.1], \"Group2_vs_Group4\":[0.1, 0.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an \"AlignRepresentations\" instance\n",
    "align_representation = AlignRepresentations(\n",
    "    config=config,\n",
    "    representations_list=representations,   \n",
    "    \n",
    "    # pairs_computed : user can limit the pairs here\n",
    "    pairs_computed = pairs_computed,\n",
    "    \n",
    "    # specific_eps_list : user can define a specific range of epsilon for some pairs.\n",
    "    specific_eps_list = specific_eps_list,\n",
    "    \n",
    "    # histogram matching : this will adjust the histogram of target to that of source.\n",
    "    histogram_matching=False,\n",
    "    \n",
    "    # metric : The metric for computing the distance between the embeddings. Please set the metric tha can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    metric=\"cosine\", \n",
    "\n",
    "    # main_results_dir : folder or file name when saving the result\n",
    "    main_results_dir = \"../results\",\n",
    "    \n",
    "    # data_name : Please rewrite this name if users want to use their own data.\n",
    "    data_name = data_select,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When you want to re-run the optimization process for specific pairs only\n",
    "You can change the specific pairs to be computed by setting `pair_computed` as follows.   \n",
    "You can also change the epsilon range `specific_eps_list` as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User can only re-run the optimization for specific pairs by using `set_pair_computed`.\n",
    "\n",
    "# pairs_computed = [\"Group1\", \"Group2_vs_Group4\"] \n",
    "# pairs_computed = [\"AlexNet_vs_ResNet18\", \"ResNet50_vs_VGG19\", \"VGG16_vs_VGG19\"] # can be used for DNN\n",
    "# align_representation.set_pair_computed(pairs_computed)\n",
    "\n",
    "# Also, user can also re-define the epsilon range for some pairs by using `set_specific_eps_list`. The rest of them will be computed with `config.eps_list`. \n",
    "# If `specific_only` is True (default is False), only these pairs will be computed and the rest of them were skipped.\n",
    "\n",
    "# specific_eps_list = {'Group1': [0.02, 0.1], \"Group2_vs_Group4\":[0.1, 0.2]}\n",
    "# align_representation.set_specific_eps_list(specific_eps_list, specific_only=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisualizationConfig\n",
    "You can set the parameters for the visualization of the matrices, the embeddings and/or evaluation figures after the alignment was done.   \n",
    "Here, we introduce all the parameters that will be used for this instance.   \n",
    "Some of them may be modified later for each dataset.   \n",
    "Please keep in mind you can also get the raw results data if you want to customize the figures by yourself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_config = VisualizationConfig(\n",
    "    ### If you want to save the figure only, and don't show them, please set show_figure = False.\n",
    "    show_figure = True,\n",
    "    \n",
    "    ### Please set the parameters below that can be used in \"matplotlib.pyplot\"\n",
    "    figsize=(8, 6),\n",
    "    cbar_ticks_size=15,\n",
    "    ticks_size=20,\n",
    "    xticks_rotation=90,\n",
    "    yticks_rotation=0,\n",
    "    title_size=20,\n",
    "    legend_size=5,\n",
    "    xlabel=None,\n",
    "    xlabel_size=15,\n",
    "    ylabel=None,\n",
    "    ylabel_size=15,\n",
    "    zlabel=None,\n",
    "    zlabel_size=15,\n",
    "    color_labels=None,\n",
    "    color_hue=None,\n",
    "    markers_list=None,\n",
    "    marker_size=30,\n",
    "    color = 'C0',\n",
    "    cmap = 'cividis',\n",
    "    \n",
    "    ### Set ticks of the object label or the coarce category labels.\n",
    "    # If both are False, no tick will be shown in the figure.\n",
    "    ot_object_tick=False,\n",
    "    ot_category_tick=False,\n",
    "    \n",
    "    ### Set the parameters for showing the boundary of the coarce category labels in the OT figure if the dataset have them. \n",
    "    # If not, please set draw_category_line = False.\n",
    "    # Note that please set ot_category_tick = True when drawing the category line.\n",
    "    \n",
    "    draw_category_line=False,\n",
    "    category_line_color='C2',\n",
    "    category_line_alpha=0.2,\n",
    "    category_line_style='dashed',\n",
    "    \n",
    "    \n",
    "    ### From here below, user can define the parameters using for evaluation figure after alignment computation is done.\n",
    "    # It is not necessary to set them here becuase we prepared \"set_params\" to add or re-define the parameters for making the figures. \n",
    "    # So, all the parameters below will be introduced after the alignment block.\n",
    "    plot_eps_log=eps_log,\n",
    "    lim_eps=None,\n",
    "    lim_gwd=None,\n",
    "    lim_acc=None,  \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show dissimilarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset No.1 : color \n",
    "if data_select == \"color\":\n",
    "    sim_mat_format = \"default\"\n",
    "    \n",
    "    visualize_config = VisualizationConfig(\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        ot_object_tick=True,\n",
    "    )\n",
    "    \n",
    "    visualize_hist = VisualizationConfig(figsize=(8, 6), color='C0')\n",
    "    \n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format = sim_mat_format, \n",
    "        visualization_config = visualize_config,\n",
    "        visualization_config_hist = visualize_hist,\n",
    "        show_distribution=False, # if True, the histogram figure of the sim_mat will be shown. visualization_config_hist will be used for adjusting this figure.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset No.2 : THINGS\n",
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "    visualize_config = VisualizationConfig(\n",
    "        show_figure = True,\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        cmap = 'Blues',\n",
    "        cbar_ticks_size=20,\n",
    "        \n",
    "        ot_object_tick=False,\n",
    "        ot_category_tick=True,\n",
    "        \n",
    "        # Note that please set ot_category_tick = True when drawing the category line.\n",
    "        draw_category_line=True,\n",
    "        category_line_color='C4',\n",
    "        category_line_alpha=0.5,\n",
    "        category_line_style='dashed',\n",
    "    )\n",
    "    \n",
    "    visualize_hist = VisualizationConfig(figsize=(8, 6), color='C0')\n",
    "    \n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format=sim_mat_format, \n",
    "        visualization_config=visualize_config,\n",
    "        visualization_config_hist=visualize_hist,\n",
    "        fig_dir=None,\n",
    "        show_distribution=False,\n",
    "        ticks='category'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset No.3 : DNN\n",
    "if data_select == \"DNN\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "    \n",
    "    visualize_config = VisualizationConfig(\n",
    "        show_figure = True,\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        cmap='rocket',\n",
    "        cbar_ticks_size=10,\n",
    "        \n",
    "        ot_object_tick=False,\n",
    "        ot_category_tick=True,\n",
    "        \n",
    "        draw_category_line=True,\n",
    "        category_line_color='black',\n",
    "        category_line_alpha=0.4,\n",
    "        category_line_style='dashed',\n",
    "        \n",
    "        plot_eps_log = eps_log, \n",
    "    )\n",
    "    \n",
    "    visualize_hist = VisualizationConfig(figsize=(8, 6), color='C0')\n",
    "    \n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format=sim_mat_format, \n",
    "        visualization_config=visualize_config,\n",
    "        visualization_config_hist=visualize_hist,\n",
    "        fig_dir=None,\n",
    "        show_distribution=False,\n",
    "        ticks='category'\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reperesentation Similarity Aanalysis (RSA)\n",
    "This performs a conventional representation similarity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for computing RSA\n",
    "# metric = \"pearson\" or \"spearman\" by scipy.stats\n",
    "# method = \"normal\" or \"all\"\n",
    "#     \"normal\" : perform RSA with the upper-triangle matrix of sim_mat\n",
    "#     \"all\" : perform RSA with the full matrix of sim_mat\n",
    "# The result of RSA for each pair will be stored in align_representation.RSA_corr\n",
    "align_representation.RSA_get_corr(metric = \"pearson\", method = 'all')\n",
    "\n",
    "# print(align_representation.RSA_corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GWOT\n",
    "The optimization results are saved in the folder named \"config.data_name\" + \"representations.name\" vs \"representation.name\".  \n",
    "If you want to change the name of the saved folder, please make changes to \"config.data_name\" and \"representations.name\" (or change the \"filename\" in the code block below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the computation has been completed and there is no need to recompute, set \"compute_OT\" to False. In this case, the previously calculated OT plans will be loaded.\n",
    "# If users want to compare both numpy and torch, \"compute_OT\" needs to be True (e.g. an expected case is that users wants to change the \"to_types\" once after the computation is finished)\n",
    "compute_OT = False\n",
    "\n",
    "### If the previous optimization data exists, you can delete it.\n",
    "# If you are attempting the same optimization with a different epsilon search space (eps_list), it is recommended to delete the previous results.\n",
    "# Setting delete_results=True will delete both the database and the directory where the results of the previous optimization are stored.\n",
    "# This function only works when n_job = 1, all the computed results exist, and \"compute_OT\" is set to False.\n",
    "# The code will prompt for confirmation before deleting all the results.\n",
    "delete_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GWOT is performed by appling the method `gw_alignment` to the instance of `AlignRepresentations` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\" # \"sorted\" : the rows and columns of the OT plans are sorted by the coarce categories. If there is no need for sorting, set it to \"default\".\n",
    "    \n",
    "    visualize_config.set_params(\n",
    "        # user can re-define the parameter if necessary.\n",
    "        show_figure=True,  \n",
    "        cmap = 'viridis',\n",
    "        category_line_color='black',\n",
    "        category_line_alpha=0.2,\n",
    "    )\n",
    "\n",
    "    ot_list = align_representation.gw_alignment(\n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        \n",
    "        ## return_data : If True, the \"OT_format\" data will be returned in `ot_list`.\n",
    "        return_data = False,\n",
    "        \n",
    "        ## return_figure : If True, figure of OT will be shown in this notebook. Figure is always saved in the \"figure\" folder.\n",
    "        return_figure = True,\n",
    "        \n",
    "        OT_format = sim_mat_format,\n",
    "        visualization_config = visualize_config,\n",
    "        \n",
    "        ## show_log : if True, this will show the figures how the GWD was optimized. \n",
    "        # So, please set the parameters of them before this function starts to compute.\n",
    "        # The details of it will be explained in the next block.\n",
    "        show_log=False, \n",
    "        \n",
    "        ## fig_dir : you can define the path to which you save the figures (.png). If None, the figures will be saved in the same subfolder in \"results_dir\"\n",
    "        fig_dir=None,\n",
    "        \n",
    "        ## ticks : you can use \"objects\" or \"category\" or \"None\"\n",
    "        ticks='category', \n",
    "        \n",
    "        save_dataframe=False,\n",
    "        \n",
    "        ## change_sampler_seed : If True, the random seed will be changed for each pair, else, the same seed defined in the next parameter will be used.  Default is False.\n",
    "        change_sampler_seed=True, \n",
    "        \n",
    "        ## fix_sampler_seed : this seed is used mainly for random sampler and TPE samapler. you can set any int (>= 0) value for sampler's seed. Default is 42.\n",
    "        fix_sampler_seed = 42, \n",
    "        \n",
    "        ## parallel_method : user can change the way of parallel computation, \"multiprocess\" or \"multithread\".\n",
    "        # \"multithread\" may be effective for most case, please choose the best one for user's environment.\n",
    "        parallel_method=\"multithread\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"color\":\n",
    "    visualize_config = VisualizationConfig(\n",
    "        show_figure=True,\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        ot_object_tick=True,\n",
    "        plot_eps_log=eps_log,\n",
    "    )\n",
    "\n",
    "    align_representation.gw_alignment(\n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        return_data = False,\n",
    "        return_figure = False,\n",
    "        OT_format = sim_mat_format, # \"default\"\n",
    "        visualization_config = visualize_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"DNN\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "\n",
    "    align_representation.gw_alignment(\n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        return_data = False,\n",
    "        return_figure = True,\n",
    "        OT_format = sim_mat_format,\n",
    "        visualization_config = visualize_config,\n",
    "        show_log=False, \n",
    "        ticks=\"category\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluation and Visualization\n",
    "Finally, you can evaluate and visualize the unsupervise alignment of GWOT.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show how the GWD was optimized\n",
    "`show_optimization_log` will make two figures to show both the relationships between epsilons (x-axis) and GWD (y-axis), and between accuracy (x-axis) and GWD (y-axis).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### user can define the parameters using for evaluation figure after alignment computation is done.\n",
    "if data_select == \"THINGS\":\n",
    "    visualize_config.set_params(\n",
    "        # user can re-define the parameter if necessary.\n",
    "        show_figure=False, \n",
    "        \n",
    "        # plot_eps_log : user can choose the scale of eps in the figure. True = log scale, False = linear scale.\n",
    "        plot_eps_log=eps_log,\n",
    "        \n",
    "        # lim_eps : define the range of eps to show in the figure. \n",
    "        # If None, default setting of matplotlib to detect the range will be used.\n",
    "        lim_eps=None,\n",
    "        \n",
    "        # lim_gwd : define the range of GWD to show in the figure. \n",
    "        # If None, default setting of matplotlib to detect the range will be used.\n",
    "        lim_gwd=None,\n",
    "        \n",
    "        # lim_acc : define the range of accuracy to show in the figure. the unit of accuracy is percentage. So, maximum is 100.\n",
    "        # If None, default setting of matplotlib to detect the range will be used.\n",
    "        lim_acc=[0, 100],      \n",
    "    )\n",
    "visualize_config.set_params(cmap='rocket',lim_acc=[0, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show how the GWD was optimized (evaluation figure)\n",
    "# show both the relationships between epsilons and GWD, and between accuracy and GWD\n",
    "align_representation.show_optimization_log(fig_dir=None, visualization_config=visualize_config) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the accuracy of the unsupervised alignment\n",
    "There are two ways to evaluate the accuracy.  \n",
    "1. Calculate the accuracy based on the OT plan. \n",
    "- For using this method, please set the parameter `eval_type = \"ot_plan\"` in \"calc_accuracy()\".\n",
    "  \n",
    "2. Calculate the matching rate based on the k-nearest neighbors of the embeddings.\n",
    "-  For using this method, please set the parameter `eval_type = \"k_nearest\"` in \"calc_accuracy()\".\n",
    "\n",
    "For both cases, the accuracy evaluation criterion can be adjusted by considering \"top k\".  \n",
    "By setting \"top_k_list\", you can observe how the accuracy increases as the criterion is relaxed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the accuracy based on the OT plan. \n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"ot_plan\")\n",
    "align_representation.plot_accuracy(eval_type = \"ot_plan\", scatter = True)\n",
    "\n",
    "top_k_accuracy = align_representation.top_k_accuracy # you can get the dataframe directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if data_select != 'DNN':\n",
    "## Calculate the matching rate based on the k-nearest neighbors of the embeddings.\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"k_nearest\")\n",
    "align_representation.plot_accuracy(eval_type = \"k_nearest\", scatter = True)\n",
    "\n",
    "k_nearest_matching_rate = align_representation.k_nearest_matching_rate # you can get the dataframe directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calclate the category level accuracy\n",
    "\n",
    "# If the data has the coarse category labels, you can observe the category level accuracy.\n",
    "# This accuracy is calculated based on the OT plan.\n",
    "if data_select == \"THINGS\" or data_select == \"DNN\":\n",
    "    align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"category\", category_mat=category_mat)\n",
    "    align_representation.plot_accuracy(eval_type = \"category\", scatter = True)\n",
    "\n",
    "    category_level_accuracy = align_representation.category_level_accuracy # you can get the dataframe directly "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the aligned embeddings\n",
    "Using optimized transportation plans, you can align the embeddings of each representation to a shared space in an unsupervised manner.  \n",
    "The `\"pivot\"` refers to the target embeddings space to which the other embeddings will be aligned.   \n",
    "You have the option to designate the `\"pivot\"` as one of the representations or the barycenter.  \n",
    "Please ensure that 'pair_number_list' includes all pairs between the pivot and the other Representations.  \n",
    "\n",
    "If you wish to utilize the barycenter, please make use of the method `AlignRepresentation.barycenter_alignment()`.  \n",
    "You can use it in the same manner as you did with `AlignRepresentation.gw_alignment()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color labels and coarse category labels if exist.\n",
    "# If there are a large number of objects within each group, such as in the case of THINGS data, visualizing all the points may not be meaningful. \n",
    "# In such cases, it is necessary to specify specific coarse category labels that you would like to visualize.\n",
    "if data_select == \"THINGS\":\n",
    "    category_name_list = [\"bird\", \"insect\", \"plant\", \"clothing\",  \"furniture\", \"fruit\", \"drink\", \"vehicle\"] # please specify the categories that you would like to visualize.\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)   \n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat, category_name_list, show_numbers = True)  \n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        figsize=(8, 8), \n",
    "        xlabel=\"PC1\",\n",
    "        ylabel=\"PC2\", \n",
    "        zlabel=\"PC3\", \n",
    "        marker_size=6,\n",
    "        legend_size=10\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3,  # the dimensionality of the space the points are embedded in. You can choose either 2 or 3.\n",
    "        pivot=0, # the number of one of the representations or the \"barycenter\".\n",
    "        visualization_config=visualization_embedding,\n",
    "        category_name_list=category_name_list, \n",
    "        category_idx_list=category_idx_list, \n",
    "        num_category_list=num_category_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == 'color':\n",
    "    file_path = \"../data/color_dict.csv\"\n",
    "    data_color = pd.read_csv(file_path)\n",
    "    color_labels = data_color.columns.values # Set color labels if exist\n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        color_labels=color_labels, # If there is no specific color labels, please set it to \"None\". Color labels will be automatically generated in that case. \n",
    "        color_hue=None, # If \"color_labels=None\", you have the option to choose the color hue as either \"cool\", \"warm\", or \"None\".\n",
    "        figsize=(9, 9), \n",
    "        xlabel=\"PC1\", \n",
    "        ylabel=\"PC2\",\n",
    "        zlabel=\"PC3\", \n",
    "        legend_size=10\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3, # the dimensionality of the space the points are embedded in. You can choose either 2 or 3.\n",
    "        pivot=0, # the number of one of the representations or the \"barycenter\".\n",
    "        visualization_config=visualization_embedding\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"DNN\":\n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        figsize=(12, 12), \n",
    "        xlabel=\"PC1\",\n",
    "        ylabel=\"PC2\", \n",
    "        zlabel=\"PC3\",\n",
    "        xlabel_size=10,\n",
    "        ylabel_size=10,\n",
    "        zlabel_size=10,\n",
    "        marker_size=6,\n",
    "        legend_size=10\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3,  \n",
    "        pivot=0,\n",
    "        visualization_config=visualization_embedding,\n",
    "        category_name_list=category_name_list, \n",
    "        category_idx_list=category_idx_list, \n",
    "        num_category_list=num_category_list,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Delete Results\n",
    "\n",
    "If you want to delete both the directory and the database where the calculation results are stored all at once, you can use drop_gw_alignment_files.  \n",
    "Please be very careful because this operation is irreversible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align_representation.drop_gw_alignment_files(drop_all=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
