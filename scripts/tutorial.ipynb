{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tutorial for Gromov-Wassserstein unsupervised alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from src.align_representations import Representation, AlignRepresentations, OptimizationConfig, VisualizationConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Prepare the dissimilarity matrices or the embeddings from the data\n",
    "First, you need to prepare the dissimilarity matrices or the embeddings from your data.  \n",
    "\n",
    "The unit of unsupervised alignment is an instance of the \"Representation\" class. This class has variables such as \"name\" and either \"sim_mat\" or \"embedding\". You need to assign values to these variables.  \n",
    "These instances are stored in \"representations\" and later passed to the \"AlignRepresentations\" class.\n",
    "\n",
    "## Load data\n",
    "You have the option to select the data from the following choices:\n",
    "1. 'color': human similarity judgements of 93 colors for 5 paricipants groups\n",
    "2. 'THINGS' : human similarity judgements of 1854 objects for 4 paricipants groups\n",
    "\n",
    "\"data_select\" in next code block determines which data is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of representations where the instances of \"Representation\" class are included\n",
    "representations = list()\n",
    "\n",
    "# select data\n",
    "data_select = \"THINGS\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No1. `color`\n",
    "In this case, we directly assign the dissimilarity matrices of 93 colors to \"Representation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create \"Representation\" instance\n",
    "if data_select == 'color':\n",
    "    n_representations = 5 # Set the number of the instanses of \"Representation\". This number must be equal to or less than the number of the groups.\n",
    "    metric = \"euclidean\" # Please set the metric that can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    \n",
    "    data_path = '../data/num_groups_5_seed_0_fill_val_3.5.pickle'\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    sim_mat_list = data[\"group_ave_mat\"]\n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\" # \"name\" will be used as a filename for saving the results\n",
    "        sim_mat = sim_mat_list[i] # the dissimilarity matrix of the i-th group\n",
    "        # make an instance \"Representation\" with settings \n",
    "        representation = Representation(\n",
    "            name=name, \n",
    "            metric=metric,\n",
    "            sim_mat=sim_mat,  #: np.ndarray\n",
    "            embedding=None,   #: np.ndarray \n",
    "            get_embedding=True, # If true, the embeddings are computed from the dissimilarity matrix automatically using the MDS function. Default is False. \n",
    "            MDS_dim=3, # If \"get embedding\" is True, please set the dimensions of the embeddings.\n",
    "            object_labels=None,\n",
    "            category_name_list=None,\n",
    "            num_category_list=None,\n",
    "            category_idx_list=None,\n",
    "            func_for_sort_sim_mat=None,\n",
    "       ) \n",
    "        representations.append(representation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No.2 `THINGS`\n",
    "In this case, we assign the embeddings of each object to \"Representation\". This class will automatically compute the dissimilarity matrices with the embeddings.  \n",
    "Furthermore, this dataset includes coarse category labels, and we will now demonstrate how to utilize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    # define the coarce category labels\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)\n",
    "    \n",
    "    # calculate the parameters for the coarce category labels\n",
    "    # Please prepare equivalent parameters when using other datasets.\n",
    "    from src.utils.utils_functions import get_category_data, sort_matrix_with_categories # get_category_data and sort_matrix_with_categories are functions specialied for this dataset\n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat)\n",
    "    \n",
    "    n_representations = 4 # Set the number of the instanses of \"Representation\". This number must be equal to or less than the number of the groups.\n",
    "    metric = \"euclidean\" # Please set the metric that can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    \n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\"\n",
    "        embedding = np.load(f\"../data/THINGS_embedding_Group{i+1}.npy\")[0]\n",
    "        \n",
    "        representation = Representation(\n",
    "            name=name, \n",
    "            embedding=embedding, # the dissimilarity matrix will be computed with this embedding.\n",
    "            metric=metric,\n",
    "            get_embedding=False, # If there is the embeddings, plese set this variable \"False\".\n",
    "            object_labels=object_labels,\n",
    "            category_name_list=category_name_list,\n",
    "            category_idx_list=category_idx_list,\n",
    "            num_category_list=num_category_list,\n",
    "            func_for_sort_sim_mat=sort_matrix_with_categories\n",
    "        )\n",
    "        \n",
    "        representations.append(representation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Set the parameters for the optimazation of GWOT\n",
    "\n",
    "## Optimization Config  \n",
    "\n",
    "#### Most important parameters to check for your application:\n",
    "`eps_list, num_trial` are essential for computing the GW alignment.  \n",
    "You need to choose the appropriate ranges of the epsilon, `eps_list`.  \n",
    "If the epsilon is not in the appropriate ranges, the optimization may not work properly.  \n",
    "Also, the epsilon range is critical for finding good local optimum.  \n",
    "\n",
    "For other parameters, please start by trying the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    eps_list_tutorial = [1,10]\n",
    "if data_select == \"color\":\n",
    "    eps_list_tutorial = [0.02, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OptimizationConfig(\n",
    "    ### Set the range of the epsilon\n",
    "    # set the minimum value and maximum value for 'tpe' sampler\n",
    "    # for 'grid' or 'random' sampler, you can also set the step size\n",
    "    eps_list = eps_list_tutorial, # [1, 10] for THINGS data, [0.02, 0.2] for colors data\n",
    "    eps_log = True, # whether epsilon is sampled at log scale or not\n",
    "    num_trial = 4, # set the number of trials, i.e., the number of epsilon values evaluated in optimization. default : 4\n",
    "    sinkhorn_method='sinkhorn_log', # please choose the method of sinkhorn implemented by POT (URL : https://pythonot.github.io/gen_modules/ot.bregman.html#id87). For using GPU, \"sinkhorn_log\" is recommended.\n",
    "    \n",
    "    ### Set the device ('cuda' or 'cpu') and variable type ('torch' or 'numpy')\n",
    "    to_types = 'torch', # user can choose \"numpy\" or \"torch\". please set \"torch\" if one wants to use GPU.\n",
    "    device = 'cuda', # \"cuda\" or \"cpu\"; for numpy, only \"cpu\" can be used. \n",
    "    \n",
    "    ### Parallel Computation (requires n_jobs > 1, available both for numpy and torch)\n",
    "    n_jobs = 4, # n_jobs : the number of worker to compute. if n_jobs = 1, normal computation will start. \"Multithread\" is used for Parallel computation.\n",
    "    multi_gpu = True, # This parameter is only for \"torch\". # \"True\" : all the GPU installed in your environment are used, \"list (e.g.[0,2,3])\"\" : cuda:0,2,3, and \"False\" : single gpu (or cpu for numpy) will use.\n",
    "    \n",
    "    ### Set the db_params to create database URL to store the optimization results (either PyMySQL or SQLite. For using PyMySQL, some additional setting beforehand will be needed).  \n",
    "    # The database URL in sqlalchemy is like \"dialect+driver://username:password@host:port/database\". See the following page for details. https://docs.sqlalchemy.org/en/20/core/engines.html\n",
    "    # If you want to use SQLite, it's enough to set \"db_params={\"drivername\": \"sqlite\"}\".\n",
    "    # This package generates 1 database per each study.\n",
    "\n",
    "    db_params={\"drivername\": \"sqlite\"},\n",
    "    # db_params={\"drivername\": \"mysql+pymysql\", \"username\": \"root\", \"password\": \"****\", \"host\": \"localhost\"},\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # initialization of transportation plan\n",
    "    # 'uniform': uniform matrix, 'diag': diagonal matrix', random': random matrix, 'permutation': permutation matrix\n",
    "    # you can select multiple options (e.g. init_plans_list = ['uniform', 'random'])\n",
    "    init_plans_list = ['random'],\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # n_iter : the number of random initial matrices for 'random' or 'permutation' options：default: 1\n",
    "    # max_iter : the maximum number of iteration for GW optimization: default: 200\n",
    "    n_iter = 1,\n",
    "    max_iter = 200,\n",
    "    \n",
    "    ### folder or file name when saving the result\n",
    "    # The ptimization results are saved in the folder named \"config.data_name\" + \"representations.name\" vs \"representation.name\".  \n",
    "    # If you want to change the name of the saved folder, please make changes to \"config.data_name\" and \"representations.name\".\n",
    "    data_name = data_select, # Please rewrite this name if users want to use their own data.\n",
    "    \n",
    "    ### choose sampler implemented by Optuna\n",
    "    # 1. 'random': randomly select epsilon between the range of epsilon\n",
    "    # 2. 'grid': grid search between the range of epsilon\n",
    "    # 3. 'tpe': Bayesian sampling\n",
    "    sampler_name = 'tpe',\n",
    "    sampler_seed = 42, # this seed is used mainly for random sampler and TPE samapler. \n",
    "    \n",
    "    ### choose pruner\n",
    "    # 1. 'median': Pruning if the score is below the past median at a certain point in time  \n",
    "    #     n_startup_trials: Do not activate the pruner until this number of trials has finished  \n",
    "    #     n_warmup_steps: Do not activate the pruner for each trial below this step  \n",
    "        \n",
    "    # 2. 'hyperband': Use multiple SuccessiveHalvingPrunerd that gradually longer pruning decision periods and that gradually stricter criteria  \n",
    "    #     min_resource: Do not activate the pruner for each trial below this step  \n",
    "    #     reduction_factor: How often to check for pruning. Smaller values result in more frequent pruning checks. Between 2 to 6.  \n",
    "        \n",
    "    # 3. 'nop': no pruning\n",
    "    pruner_name = 'hyperband',\n",
    "    pruner_params = {'n_startup_trials': 1, \n",
    "                     'n_warmup_steps': 2, \n",
    "                     'min_resource': 2, \n",
    "                     'reduction_factor' : 3\n",
    "                    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisualizationConfig\n",
    "You can set the parameters for the visualization of the matrices or the embeddings.\n",
    "\n",
    "Here, we aim to introduce all the parameters that will be used for this instance, keeping in mind that some of them may be modified later for each dataset.\n",
    "\n",
    "Please keep in mind you can also get the raw results data if you want to make the figures by yourself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizationconfig = VisualizationConfig(\n",
    "    ### Please set the parameters below that can be used in \"mttplotlib.pyplot\"\n",
    "    figsize=(8, 6), \n",
    "    title_size = 15, \n",
    "    cmap = 'cividis',\n",
    "    cbar_ticks_size=20,\n",
    "    ticks_size=5,\n",
    "    xticks_rotation=90,\n",
    "    yticks_rotation=0,\n",
    "    legend_size=5,\n",
    "    xlabel=None,\n",
    "    xlabel_size=15,\n",
    "    ylabel=None,\n",
    "    ylabel_size=15,\n",
    "    zlabel=None,\n",
    "    zlabel_size=15,\n",
    "    color_labels=None,\n",
    "    color_hue=None,\n",
    "    markers_list=None,\n",
    "    marker_size=30,\n",
    "    \n",
    "    ### Set the parameters for showing the boundary of the coarce category labels if the dataset have them. If not, please set draw_category_line = False.\n",
    "    draw_category_line=True,\n",
    "    category_line_color='C2',\n",
    "    category_line_alpha=0.2,\n",
    "    category_line_style='dashed',\n",
    "    \n",
    "    ### If you want to save the figure only, but don't show them, please set show_figure = False.\n",
    "    show_figure = True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Unsupervised alignment between Representations\n",
    "\"AlignRepresentations\" is the class for performing the unsupervised alignment among the instanses of \"Representation\".  \n",
    "This class has methods for Representation Similarity Analysis (RSA), Gromov-Wasserstein (GW) alignment, and the evaluation of the GW alignment.  \n",
    "\n",
    "By default, the instance applis GW alignment to all pairs in the `representations` defined at the begining of this notebook.   \n",
    "If you want to limit the pairs to which GW alignment is applied, please set “AlignRepresentations.pair_number_list”. (e.g. pair_number_list = [[0, 1], [0, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an \"AlignRepresentations\" instance\n",
    "align_representation = AlignRepresentations(\n",
    "    representations_list=representations,\n",
    "    pair_number_list=\"all\", # If you want to limit the pairs to which GW alignment is applied, please set “AlignRepresentations.pair_number_list”. (e.g. pair_number_list = [[0, 1], [0, 2]])\n",
    "    histogram_matching=False,\n",
    "    config=config,\n",
    "    metric=\"cosine\", # The metric for computing the distance between the embeddings. Please set the metric tha can be used in \"scipy.spatical.distance.cdist()\".\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show dissimilarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset No.1 : color \n",
    "if data_select == \"color\":\n",
    "    sim_mat_format = \"default\"\n",
    "    visualize_matrix = VisualizationConfig(figsize=(8, 6), title_size = 15)\n",
    "    visualize_hist = VisualizationConfig(figsize=(8, 6), cmap='C0')\n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format = sim_mat_format, \n",
    "        visualization_config = visualize_matrix,\n",
    "        visualization_config_hist = visualize_hist,\n",
    "        show_distribution=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset No.2 : THINGS\n",
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "    visualize_matrix = VisualizationConfig(\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        cmap = 'Blues',\n",
    "        cbar_ticks_size=20,\n",
    "        \n",
    "        draw_category_line=True,\n",
    "        category_line_color='C4',\n",
    "        category_line_alpha=0.5,\n",
    "        category_line_style='dashed',\n",
    "       \n",
    "        )\n",
    "    \n",
    "    visualize_hist = VisualizationConfig(figsize=(8, 6), cmap='C0')\n",
    "    \n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format=sim_mat_format, \n",
    "        visualization_config=visualize_matrix,\n",
    "        visualization_config_hist=visualize_hist,\n",
    "        fig_dir=None,\n",
    "        show_distribution=False,\n",
    "        ticks='category'\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reperesentation Similarity Aanalysis (RSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for computing RSA\n",
    "# metric = \"pearson\" or \"spearman\" by scipy.stats\n",
    "# method = \"normal\" or \"all\"\n",
    "#     \"normal\" : perform RSA with the upper-triangle matrix of sim_mat\n",
    "#     \"all\" : perform RSA with the full matrix of sim_mat\n",
    "align_representation.RSA_get_corr(metric = \"pearson\", method = 'all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform GW Alignment\n",
    "The optimization results are saved in the folder named \"config.data_name\" + \"representations.name\" vs \"representation.name\".  \n",
    "If you want to change the name of the saved folder, please make changes to \"config.data_name\" and \"representations.name\" (or change the \"filename\" in the code block below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the computation has been completed and there is no need to recompute, set \"compute_OT\" to False. \n",
    "# In this case, the previously calculated OT plans will be loaded.\n",
    "# If users want to compare both numpy and torch, \"compute_OT\" needs to be True \n",
    "# (e.g. users wants to change the \"to_types\" once after the computation is finished)\n",
    "compute_OT = False\n",
    "\n",
    "### If the previous optimization data exists, you can delete it.\n",
    "# If you are attempting the same optimization with a different epsilon search space (eps_list), it is recommended to delete the previous results.\n",
    "# Setting delete_results=True will delete both the database and the directory where the results of the previous optimization are stored.\n",
    "# This function only works when n_job = 1, all the computed results exist, and \"compute_OT\" is set to False.\n",
    "# The code will prompt for confirmation before deleting all the results.\n",
    "delete_results = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\" # \"sorted\" : the rows and columns of the OT plans are sorted by the coarce categories. If there is no need for sorting, set it to \"default\".\n",
    "    visualize_matrix = VisualizationConfig(\n",
    "        figsize=(8, 6), \n",
    "        title_size=15,\n",
    "        cbar_ticks_size=15,\n",
    "        draw_category_line=True,\n",
    "        category_line_color='C2',\n",
    "        category_line_alpha=0.2,\n",
    "        category_line_style='dashed',\n",
    "    )\n",
    "\n",
    "    ot_list = align_representation.gw_alignment(\n",
    "        results_dir = \"../results\",\n",
    "        \n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        \n",
    "        return_data = False, # If True, the row data will be returned in `ot_list`.\n",
    "        return_figure = True,\n",
    "        \n",
    "        OT_format = sim_mat_format,\n",
    "        visualization_config = visualize_matrix,\n",
    "        show_log=False, # if True, this will show the figures how the GWD was optimized.\n",
    "        fig_dir=None, # you can define the path to which you save the figures (.png). If None, the figures will be saved in the same subfolder in \"results_dir\"\n",
    "        ticks='category', # you can use \"objects\" or \"category\" or \"None\"\n",
    "        \n",
    "        filename=None, # default is None. If None, the database name and folder name to save the results will automatically made. \n",
    "        save_dataframe=False,\n",
    "    )\n",
    "\n",
    "if data_select == \"color\":\n",
    "    visualize_matrix = VisualizationConfig(figsize=(10, 10), title_size = 15, show_figure=True)\n",
    "\n",
    "    align_representation.gw_alignment(\n",
    "        results_dir = \"../results\",\n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        return_data = False,\n",
    "        return_figure = True,\n",
    "        OT_format = sim_mat_format, # \"default\"\n",
    "        visualization_config = visualize_matrix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show how the GWD was optimized\n",
    "#  show both the relationships between epsilons and GWD, and between accuracy and GWD\n",
    "visualize_matrix = VisualizationConfig(figsize=(8,6), cmap='C0', show_figure=False)\n",
    "align_representation.show_optimization_log(\n",
    "    results_dir=\"../results\",\n",
    "    filename=None,\n",
    "    fig_dir=None,\n",
    "    visualization_config=visualize_matrix,\n",
    ") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the accuracy of the unsupervised alignment\n",
    "There are two ways to evaluate the accuracy.  \n",
    "1. Calculate the accuracy based on the OT plan. \n",
    "- For using this method, please set the parameter `eval_type = \"ot_plan\"` in \"calc_accuracy()\".\n",
    "  \n",
    "2. Calculate the matching rate based on the k-nearest neighbors of the embeddings.\n",
    "-  For using this method, please set the parameter `eval_type = \"k_nearest\"` in \"calc_accuracy()\".\n",
    "\n",
    "For both cases, the accuracy evaluation criterion can be adjusted by considering \"top k\".  \n",
    "By setting \"top_k_list\", you can observe how the accuracy increases as the criterion is relaxed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the accuracy based on the OT plan. \n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"ot_plan\")\n",
    "align_representation.plot_accuracy(eval_type = \"ot_plan\", scatter = True)\n",
    "\n",
    "top_k_accuracy = align_representation.top_k_accuracy # you can get the dataframe directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the matching rate based on the k-nearest neighbors of the embeddings.\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"k_nearest\")\n",
    "align_representation.plot_accuracy(eval_type = \"k_nearest\", scatter = True)\n",
    "\n",
    "k_nearest_matching_rate = align_representation.k_nearest_matching_rate # you can get the dataframe directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calclate the category level accuracy\n",
    "\n",
    "# If the data has the coarse category labels, you can observe the category level accuracy.\n",
    "# This accuracy is calculated based on the OT plan.\n",
    "if data_select == \"THINGS\":\n",
    "    align_representation.calc_category_level_accuracy(\n",
    "        category_mat=category_mat, \n",
    "        make_hist=True,\n",
    "        fig_dir=None, \n",
    "        fig_name=\"Category_level_accuracy.png\", \n",
    "        show_figure = False,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the aligned embeddings\n",
    "Using optimized transportation plans, you can align the embeddings of each representation to a shared space in an unsupervised manner.  \n",
    "The `\"pivot\"` refers to the target embeddings space to which the other embeddings will be aligned.   \n",
    "You have the option to designate the `\"pivot\"` as one of the representations or the barycenter.  \n",
    "Please ensure that 'pair_number_list' includes all pairs between the pivot and the other Representations.  \n",
    "\n",
    "If you wish to utilize the barycenter, please make use of the method `AlignRepresentation.barycenter_alignment()`.  \n",
    "You can use it in the same manner as you did with `AlignRepresentation.gw_alignment()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color labels and coarse category labels if exist.\n",
    "# If there are a large number of objects within each group, such as in the case of THINGS data, visualizing all the points may not be meaningful. \n",
    "# In such cases, it is necessary to specify specific coarse category labels that you would like to visualize.\n",
    "if data_select == \"THINGS\":\n",
    "    category_name_list = [\"bird\", \"insect\", \"plant\", \"clothing\",  \"furniture\", \"fruit\", \"drink\", \"vehicle\"] # please specify the categories that you would like to visualize.\n",
    "    category_mat = pd.read_csv(\"../data/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)   \n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat, category_name_list, show_numbers = True)  \n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        figsize=(8, 8), \n",
    "        xlabel=\"PC1\",\n",
    "        ylabel=\"PC2\", \n",
    "        zlabel=\"PC3\", \n",
    "        marker_size=6,\n",
    "        legend_size=10\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3,  # the dimensionality of the space the points are embedded in. You can choose either 2 or 3.\n",
    "        pivot=0, # the number of one of the representations or the \"barycenter\".\n",
    "        visualization_config=visualization_embedding,\n",
    "        category_name_list=category_name_list, \n",
    "        category_idx_list=category_idx_list, \n",
    "        num_category_list=num_category_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == 'color':\n",
    "    file_path = \"../data/color_dict.csv\"\n",
    "    data_color = pd.read_csv(file_path)\n",
    "    color_labels = data_color.columns.values # Set color labels if exist\n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        color_labels=color_labels, # If there is no specific color labels, please set it to \"None\". Color labels will be automatically generated in that case. \n",
    "        color_hue=None, # If \"color_labels=None\", you have the option to choose the color hue as either \"cool\", \"warm\", or \"None\".\n",
    "        figsize=(9, 9), \n",
    "        xlabel=\"PC1\", \n",
    "        ylabel=\"PC2\",\n",
    "        zlabel=\"PC3\", \n",
    "        legend_size=10\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3, # the dimensionality of the space the points are embedded in. You can choose either 2 or 3.\n",
    "        pivot=0, # the number of one of the representations or the \"barycenter\".\n",
    "        visualization_config=visualization_embedding\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Delete Results\n",
    "\n",
    "If you want to delete both the directory and the database where the calculation results are stored all at once, you can use drop_gw_alignment_files.  \n",
    "Please be very careful because this operation is irreversible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align_representation.drop_gw_alignment_files(drop_all=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
