{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial For GW Methods\n",
    "This notebook will demonstrate the main function of this toolbox.\n",
    "\n",
    "Most of the users' case, we can recommend to use these function by using `align_representations.py`, as `tutorial.ipynb` demonstrates.\n",
    "\n",
    "So, please check the `tutorial.ipynb` before checking this notebook.\n",
    "\n",
    "But, this tutorial may be helpful when employing this toolbox to our unexpected usage case which `align_representations.py` is unable to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import os\n",
    "import pickle as pkl\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "# Third Party Library\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ot\n",
    "import pandas as pd\n",
    "# import pymysql\n",
    "import scipy.io\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "# First Party Library\n",
    "from src.gw_alignment import GW_Alignment\n",
    "from src.utils.gw_optimizer import load_optimizer\n",
    "from src.utils.init_matrix import InitMatrix\n",
    "# os.chdir(os.path.dirname(__file__))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step:1 load data\n",
    "#### you can choose the following data\n",
    "1. 'DNN': representations of 2000 imagenet images in AlexNet and VGG\n",
    "1. 'color': human similarity judgements of 93 colors for 5 paricipants groups\n",
    "1. 'face': human similarity judgements of 16 faces, attended vs unattended condition in the same participant\n",
    "\n",
    "The three data above is sample data to demonstrate the computation of this toolbox.\n",
    "For the people who want to use their own data, please rewrite the `C1` and `C2` in the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_select = 'color'\n",
    "\n",
    "if data_select == 'DNN':\n",
    "    path1 = '../data/model1.pt'\n",
    "    path2 = '../data/model2.pt'\n",
    "    C1 = torch.load(path1)\n",
    "    C2 = torch.load(path2)\n",
    "elif data_select == 'color':\n",
    "    data_path = '../data/num_groups_5_seed_0_fill_val_3.5.pickle'\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    sim_mat_list = data[\"group_ave_mat\"]\n",
    "    C1 = sim_mat_list[1]\n",
    "    C2 = sim_mat_list[2]\n",
    "elif data_select == 'face':\n",
    "    data_path = '../data/faces_GROUP_interp.mat'\n",
    "    mat_dic = scipy.io.loadmat(data_path)\n",
    "    C1 = mat_dic[\"group_mean_ATTENDED\"]\n",
    "    C2 = mat_dic[\"group_mean_UNATTENDED\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "im1 = axes[0].imshow(C1, cmap='viridis')\n",
    "cbar1 = fig.colorbar(im1, ax=axes[0])\n",
    "im2 = axes[1].imshow(C2, cmap='viridis')\n",
    "cbar2 = fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "axes[0].set_title('Dissimilarity matrix #1')\n",
    "axes[1].set_title('Dissmimilarity matrix #2')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step:2 set the parameter used for computing and saving the results\n",
    "### Set the filename and folder name for saving optuna results  \n",
    "filename is also treated as optuna study_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test'\n",
    "save_path = '../results/gw_alignment/' + filename"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the device ('cuda' or 'cpu') and variable type ('torch' or 'numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "to_types = 'numpy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the database URL to store the optimization results.  \n",
    "\n",
    "The URL notation should follow the SQLAlchemy documentation:   \n",
    "https://docs.sqlalchemy.org/en/20/core/engines.html  \n",
    "\n",
    "To use remote databases, you need to start the database server beforehand. For detailed instruction, please refer to the Optuna official tutorial:  \n",
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html  \n",
    "\n",
    "When using SQLite, the database file is automatically created, so you only need to set the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the RDB to use for distributed calculations\n",
    "storage = \"sqlite:///\" + save_path +  '/' + filename + '.db'\n",
    "# storage = 'mysql+pymysql://root:olabGPU61@localhost/GridTest'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the range of epsilon\n",
    "  \n",
    "set only the minimum value and maximum value for 'tpe' sampler\n",
    "   \n",
    "for 'grid' or 'random' sampler, you can also set the step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = [1e-2, 1e-1]\n",
    "# eps_list = [1e-2, 1e-1, 1e-3]\n",
    "\n",
    "eps_log = True # use log scale if True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the params for the trial of optimize and max iteration for gw alignment computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of trials, i.e., the number of epsilon values tested in optimization: default : 20\n",
    "num_trial = 8\n",
    "\n",
    "# the maximum number of iteration for GW optimization: default: 1000\n",
    "max_iter = 200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose sampler\n",
    "1. 'random': randomly select epsilon between the range of epsilon\n",
    "1. 'grid': grid search between the range of epsilon\n",
    "1. 'tpe': Bayesian sampling\n",
    "  \n",
    "### ※ For TPE-Sampler and Grid Sampler, we recommend that `n_jobs` should be 1 because of the limitation of this algorithm.  \n",
    "We also provide parallel computation by multi-thread with `n_jobs > 1` by using the default function implemented by Optuna, but n_jobs = 1 may be safer especially for grid and TPE sampler for optuna's technical problem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_name = 'random'\n",
    "\n",
    "# the number of jobs\n",
    "n_jobs = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose pruner\n",
    "1. 'median': Pruning if the score is below the past median at a certain point in time  \n",
    "    n_startup_trials: Do not activate the pruner until this number of trials has finished  \n",
    "    n_warmup_steps: Do not activate the pruner for each trial below this step  \n",
    "      \n",
    "1. 'hyperband': Use multiple SuccessiveHalvingPrunerd that gradually longer pruning decision periods and that gradually stricter criteria  \n",
    "    min_resource: Do not activate the pruner for each trial below this step  \n",
    "    reduction_factor: How often to check for pruning. Smaller values result in more frequent pruning checks. Between 2 to 6.  \n",
    "      \n",
    "1. 'nop': no pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner_name = 'hyperband'\n",
    "pruner_params = {'n_startup_trials': 1, 'n_warmup_steps': 2, 'min_resource': 2, 'reduction_factor' : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution in the source space, and target space\n",
    "p = ot.unif(len(C1))\n",
    "q = ot.unif(len(C2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the parameters for initialization of transportation plan\n",
    "1. initialization of transportation plan\n",
    "2. 'uniform': uniform matrix, 'diag': diagonal matrix\n",
    "3. 'random': random matrix, 'permutation': permutation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of transportation plan\n",
    "# 'uniform': uniform matrix, 'diag': diagonal matrix', random': random matrix, 'permutation': permutation matrix\n",
    "init_mat_plan = 'random'\n",
    "\n",
    "# the number of random initial matrices for 'random' or 'permutation' options：default: 100\n",
    "n_iter = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the parameters for GW alignment computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please choose the method of sinkhorn implemented by POT (URL : https://pythonot.github.io/gen_modules/ot.bregman.html#id87). For using GPU, \"sinkhorn_log\" is recommended.\n",
    "sinkhorn_method='sinkhorn_log'\n",
    "\n",
    "# user can define the dtypes both for numpy and torch, \"float(=float32)\" or \"double(=float64)\". For using GPU with \"sinkhorn\", double is storongly recommended.\n",
    "data_type = \"double\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step:3 Perform GW Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate instance solves gw_alignment　\n",
    "test_gw = GW_Alignment(\n",
    "    C1, \n",
    "    C2, \n",
    "    p, \n",
    "    q, \n",
    "    save_path, \n",
    "    max_iter = max_iter, \n",
    "    n_iter = n_iter, \n",
    "    to_types = to_types,\n",
    "    data_type = data_type,\n",
    "    sinkhorn_method = sinkhorn_method,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate instance optimize gw_alignment　\n",
    "opt = load_optimizer(\n",
    "    save_path,\n",
    "    n_jobs = n_jobs,\n",
    "    num_trial = num_trial,\n",
    "    to_types = to_types,\n",
    "    method = 'optuna',\n",
    "    sampler_name = sampler_name,\n",
    "    pruner_name = pruner_name,\n",
    "    pruner_params = pruner_params,\n",
    "    n_iter = n_iter,\n",
    "    filename = filename,\n",
    "    storage = storage,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the space used for Grid Sampler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization\n",
    "# 1. choose the initial matrix for GW alignment computation.\n",
    "# init_mat_builder.implemented_init_plans(init_plans_list) will automatically remove the plans which is not implemented in this toolbox.\n",
    "init_plan = test_gw.main_compute.init_mat_builder.implemented_init_plans(init_mat_plan)\n",
    "\n",
    "# used only in grid search sampler below the two lines\n",
    "if sampler_name == \"grid\":\n",
    "    # used only in grid search sampler below the two lines\n",
    "    eps_space = opt.define_eps_space(eps_list, eps_log, num_trial)\n",
    "    search_space = {\"eps\": eps_space}\n",
    "else:\n",
    "    search_space = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute GW Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. run optimzation\n",
    "study = opt.run_study(\n",
    "    test_gw, \n",
    "    device, \n",
    "    init_mat_plan = init_mat_plan, \n",
    "    eps_list = eps_list, \n",
    "    eps_log = eps_log, \n",
    "    search_space = search_space\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step:4 View the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### View Results\n",
    "display(study.trials_dataframe().sort_values('params_eps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = study.trials_dataframe()\n",
    "best_trial = study.best_trial\n",
    "print(best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized epsilon, GWD, and transportation plan\n",
    "eps_opt = best_trial.params['eps']\n",
    "GWD_opt = best_trial.values[0]\n",
    "\n",
    "if to_types == 'numpy':\n",
    "    OT = np.load(save_path+f'/{init_mat_plan}/gw_{best_trial.number}.npy')\n",
    "elif to_types == 'torch':\n",
    "    OT = torch.load(save_path+f'/{init_mat_plan}/gw_{best_trial.number}.pt')\n",
    "    OT = OT.to('cpu').numpy()\n",
    "\n",
    "plt.imshow(OT)\n",
    "plt.title(f'OT eps:{eps_opt:.3f} GWD:{GWD_opt:.3f}')\n",
    "plt.show()\n",
    "\n",
    "df_trial = study.trials_dataframe()\n",
    "\n",
    "# evaluate accuracy of unsupervised alignment\n",
    "max_indices = np.argmax(OT, axis=1)\n",
    "accuracy = np.mean(max_indices == np.arange(OT.shape[0])) * 100\n",
    "print(f'accuracy={accuracy}%')\n",
    "\n",
    "# figure plotting epsilon as x-axis and GWD as y-axis\n",
    "sns.scatterplot(data = df_trial, x = 'params_eps', y = 'value', s = 50)\n",
    "plt.xlabel('$\\epsilon$')\n",
    "plt.ylabel('GWD')\n",
    "plt.show()\n",
    "\n",
    "#　figure plotting GWD as x-axis and accuracy as y-axis\n",
    "sns.scatterplot(data = df_trial, x = 'value', y = 'user_attrs_best_acc', s = 50)\n",
    "plt.xlabel('GWD')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
